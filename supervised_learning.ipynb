{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Supervised Optimizer\n",
    "\n",
    "From start to finish, on pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from Ising import Ising\n",
    "from model import TransformerModel\n",
    "from optimizer_supervised import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup():\n",
    "    # Setup for PyTorch:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        print(\"PyTorch is using GPU {}\".format(torch.cuda.current_device()))\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "        print(\"GPU unavailable; using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpu_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_tensor(tens, labels, opacity=0.7, size=5):\n",
    "\n",
    "    x = np.arange(tens.shape[0])\n",
    "    y = np.arange(tens.shape[1])\n",
    "    z = np.arange(tens.shape[2])\n",
    "\n",
    "    xlen = len(x)\n",
    "    ylen = len(y)\n",
    "    zlen = len(z)\n",
    "\n",
    "    print(f\"(x, y, z) = ({xlen}, {ylen}, {zlen})\")\n",
    "\n",
    "    X, Y, Z = np.meshgrid(x, y, z)\n",
    "\n",
    "    color_function = np.vectorize(lambda x, y, z: tens[x, y, z])\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=X.flatten(),\n",
    "                y=Y.flatten(),\n",
    "                z=Z.flatten(),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=size,\n",
    "                    # color=tens.swapaxes(1, 2)\n",
    "                    # .swapaxes(0, 2)\n",
    "                    # .swapaxes(1, 2)\n",
    "                    # .flatten(),  # set color to an array/list of desired values\n",
    "                    color=color_function(X, Y, Z).flatten(),\n",
    "                    colorscale=\"bupu\",  # choose a colorscale\n",
    "                    opacity=opacity,\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(xaxis_title=labels[0], yaxis_title=labels[1], zaxis_title=labels[2]),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Probabilistic Batched Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes:\n",
      " tensor([[4]], device='cuda:0')\n",
      "Dimensions of parameter space: 1\n",
      "Number of units in a feedforward layer: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\utils\\_device.py:79: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\utils\\_device.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "system_sizes = torch.arange(20, 20 + 2, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]\n",
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 1000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False\n",
    "\n",
    "print(\"Sizes:\\n\", system_sizes)\n",
    "print(\"Dimensions of parameter space:\", param_dim)\n",
    "print(\"Number of units in a feedforward layer:\", n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "gaussian_coeff = 1 / math.sqrt(2 * math.pi)\n",
    "gaussian_mean = 1.0\n",
    "gaussian_std = 0.05\n",
    "probability_distribution = lambda param: gaussian_coeff * torch.exp(\n",
    "    -0.5 * (((param - gaussian_mean) ** 2) / gaussian_std**2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset for system size 4 from TFIM_ground_states\\2024-07-24T16-19-00.994\\4.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, 0.01, 1.5).\n",
      "Hamiltonians: [<Ising.Ising object at 0x0000020DFBDFE480>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\utils\\_device.py:79: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-07-24T19-26-39.836\")\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-07-24T16-19-00.994\")\n",
    "\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(data_dir_path, batch_size=30000, samples_in_epoch=100)\n",
    "    ham.training_dataset.set_sampling_distribution(probability_distribution)\n",
    "\n",
    "print(\"Hamiltonians:\", Hamiltonians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>h</th>\n",
       "      <th>energy</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-4.271558</td>\n",
       "      <td>[0.6795005617017598, 0.09226204611238609, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-4.283337</td>\n",
       "      <td>[0.6781932021588459, 0.09419487270807067, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-4.295405</td>\n",
       "      <td>[0.6768484230388987, 0.09612717601562908, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-4.307764</td>\n",
       "      <td>[0.6754660408065457, 0.0980584315701358, 0.098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-4.320415</td>\n",
       "      <td>[0.6740459180156406, 0.09998809527863335, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-6.624868</td>\n",
       "      <td>[0.478575630155762, 0.21510241025358698, 0.215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-6.658510</td>\n",
       "      <td>[0.47687053493021014, 0.2156062783775708, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>1.48</td>\n",
       "      <td>-6.692248</td>\n",
       "      <td>[0.4751841197808484, 0.2161002547256102, 0.216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-6.726082</td>\n",
       "      <td>[0.47351625445001, 0.21658455774827437, 0.2165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-6.760009</td>\n",
       "      <td>[0.471866802527822, 0.21705940161672968, 0.217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     N     h    energy                                              state\n",
       "0    4  0.50 -4.271558  [0.6795005617017598, 0.09226204611238609, 0.09...\n",
       "1    4  0.51 -4.283337  [0.6781932021588459, 0.09419487270807067, 0.09...\n",
       "2    4  0.52 -4.295405  [0.6768484230388987, 0.09612717601562908, 0.09...\n",
       "3    4  0.53 -4.307764  [0.6754660408065457, 0.0980584315701358, 0.098...\n",
       "4    4  0.54 -4.320415  [0.6740459180156406, 0.09998809527863335, 0.09...\n",
       "..  ..   ...       ...                                                ...\n",
       "96   4  1.46 -6.624868  [0.478575630155762, 0.21510241025358698, 0.215...\n",
       "97   4  1.47 -6.658510  [0.47687053493021014, 0.2156062783775708, 0.21...\n",
       "98   4  1.48 -6.692248  [0.4751841197808484, 0.2161002547256102, 0.216...\n",
       "99   4  1.49 -6.726082  [0.47351625445001, 0.21658455774827437, 0.2165...\n",
       "100  4  1.50 -6.760009  [0.471866802527822, 0.21705940161672968, 0.217...\n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonians[0].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\utils\\_device.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\csmuser\\AppData\\Local\\Temp\\ipykernel_20112\\118968331.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(paper_checkpoint_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")\n",
    "\n",
    "results_dir = \"results\"\n",
    "paper_checkpoint_name = \"ckpt_100000_Ising_32_8_8_0.ckpt\"\n",
    "paper_checkpoint_path = os.path.join(results_dir, paper_checkpoint_name)\n",
    "checkpoint = torch.load(paper_checkpoint_path)\n",
    "testmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): TQSPositionalEncoding1D(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_Q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_K): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_V): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (amp_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (phase_head): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_supervised_batches import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x, y, z) = (101, 1, 16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          "colorscale": [
           [
            0,
            "rgb(247,252,253)"
           ],
           [
            0.125,
            "rgb(224,236,244)"
           ],
           [
            0.25,
            "rgb(191,211,230)"
           ],
           [
            0.375,
            "rgb(158,188,218)"
           ],
           [
            0.5,
            "rgb(140,150,198)"
           ],
           [
            0.625,
            "rgb(140,107,177)"
           ],
           [
            0.75,
            "rgb(136,65,157)"
           ],
           [
            0.875,
            "rgb(129,15,124)"
           ],
           [
            1,
            "rgb(77,0,75)"
           ]
          ],
          "opacity": 0.5,
          "size": 3
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "z": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ]
        }
       ],
       "layout": {
        "scene": {
         "xaxis": {
          "title": {
           "text": "batch"
          }
         },
         "yaxis": {
          "title": {
           "text": "system size"
          }
         },
         "zaxis": {
          "title": {
           "text": "parameter"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tensor(\n",
    "    Hamiltonians[0].training_dataset.sampled.unsqueeze(1).cpu().numpy(),\n",
    "    [\"batch\", \"system size\", \"parameter\"],\n",
    "    opacity=0.5,\n",
    "    size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\anaconda3\\envs\\tqs2\\Lib\\site-packages\\torch\\utils\\_device.py:79: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iter 0 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.82: 0.011234688572585583\n",
      "Epoch 0 iter 1 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.011173789389431477\n",
      "Epoch 0 iter 2 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.011273045092821121\n",
      "Epoch 0 iter 3 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.011391369625926018\n",
      "Epoch 0 iter 4 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.81: 0.011288044974207878\n",
      "Epoch 0 iter 5 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.8: 0.01133751217275858\n",
      "Epoch 0 iter 6 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.011211197823286057\n",
      "Epoch 0 iter 7 - Loss for system size tensor([4], device='cuda:0') and h-range 1.18-0.79: 0.011253876611590385\n",
      "Epoch 0 iter 8 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.81: 0.011090878397226334\n",
      "Epoch 0 iter 9 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.011218236759305\n",
      "Epoch 0 iter 10 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.011267425492405891\n",
      "Epoch 0 iter 11 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.8: 0.01095882710069418\n",
      "Epoch 0 iter 12 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.78: 0.011118277907371521\n",
      "Epoch 0 iter 13 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.010943847708404064\n",
      "Epoch 0 iter 14 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.81: 0.010988329537212849\n",
      "Epoch 0 iter 15 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.8: 0.011145125143229961\n",
      "Epoch 0 iter 16 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.81: 0.010881103575229645\n",
      "Epoch 0 iter 17 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.010846874676644802\n",
      "Epoch 0 iter 18 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.8: 0.010696545243263245\n",
      "Epoch 0 iter 19 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.010637764818966389\n",
      "Epoch 0 iter 20 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.010654223151504993\n",
      "Epoch 0 iter 21 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.010716835968196392\n",
      "Epoch 0 iter 22 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.010503588244318962\n",
      "Epoch 0 iter 23 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.010563455522060394\n",
      "Epoch 0 iter 24 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.78: 0.010502362623810768\n",
      "Epoch 0 iter 25 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.010375172831118107\n",
      "Epoch 0 iter 26 - Loss for system size tensor([4], device='cuda:0') and h-range 1.18-0.77: 0.010341172106564045\n",
      "Epoch 0 iter 27 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.79: 0.010297231376171112\n",
      "Epoch 0 iter 28 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.72: 0.010326182469725609\n",
      "Epoch 0 iter 29 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.77: 0.010240232571959496\n",
      "Epoch 0 iter 30 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.010134712792932987\n",
      "Epoch 0 iter 31 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.010008858516812325\n",
      "Epoch 0 iter 32 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.78: 0.009984424337744713\n",
      "Epoch 0 iter 33 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.009989158250391483\n",
      "Epoch 0 iter 34 - Loss for system size tensor([4], device='cuda:0') and h-range 1.18-0.81: 0.009862673468887806\n",
      "Epoch 0 iter 35 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.81: 0.009852439165115356\n",
      "Epoch 0 iter 36 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.009745115414261818\n",
      "Epoch 0 iter 37 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.8: 0.009740703739225864\n",
      "Epoch 0 iter 38 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.79: 0.009533477947115898\n",
      "Epoch 0 iter 39 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.009500945918262005\n",
      "Epoch 0 iter 40 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.81: 0.00939091295003891\n",
      "Epoch 0 iter 41 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.75: 0.00939979124814272\n",
      "Epoch 0 iter 42 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.79: 0.009214481338858604\n",
      "Epoch 0 iter 43 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.009158089756965637\n",
      "Epoch 0 iter 44 - Loss for system size tensor([4], device='cuda:0') and h-range 1.24-0.81: 0.009206647053360939\n",
      "Epoch 0 iter 45 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.78: 0.00899133738130331\n",
      "Epoch 0 iter 46 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.78: 0.008902914822101593\n",
      "Epoch 0 iter 47 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.008892535232007504\n",
      "Epoch 0 iter 48 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.78: 0.008800949901342392\n",
      "Epoch 0 iter 49 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.0086593646556139\n",
      "Epoch 0 iter 50 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.81: 0.00851629301905632\n",
      "Epoch 0 iter 51 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.00853407010436058\n",
      "Epoch 0 iter 52 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.8: 0.008448736742138863\n",
      "Epoch 0 iter 53 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.008425261825323105\n",
      "Epoch 0 iter 54 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.00839183945208788\n",
      "Epoch 0 iter 55 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.008227483369410038\n",
      "Epoch 0 iter 56 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.79: 0.008157173171639442\n",
      "Epoch 0 iter 57 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.008035748265683651\n",
      "Epoch 0 iter 58 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.008000128902494907\n",
      "Epoch 0 iter 59 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.79: 0.007981756702065468\n",
      "Epoch 0 iter 60 - Loss for system size tensor([4], device='cuda:0') and h-range 1.18-0.82: 0.00781756266951561\n",
      "Epoch 0 iter 61 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.007700543384999037\n",
      "Epoch 0 iter 62 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.81: 0.0076763685792684555\n",
      "Epoch 0 iter 63 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.007541563827544451\n",
      "Epoch 0 iter 64 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.007432153448462486\n",
      "Epoch 0 iter 65 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.007316065486520529\n",
      "Epoch 0 iter 66 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.82: 0.007296821102499962\n",
      "Epoch 0 iter 67 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.8: 0.007159078028053045\n",
      "Epoch 0 iter 68 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.007133176550269127\n",
      "Epoch 0 iter 69 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.8: 0.007069409359246492\n",
      "Epoch 0 iter 70 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.79: 0.00691060209646821\n",
      "Epoch 0 iter 71 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.81: 0.006888076197355986\n",
      "Epoch 0 iter 72 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.006810404360294342\n",
      "Epoch 0 iter 73 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.78: 0.006723212543874979\n",
      "Epoch 0 iter 74 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.006611110642552376\n",
      "Epoch 0 iter 75 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.77: 0.006497691851109266\n",
      "Epoch 0 iter 76 - Loss for system size tensor([4], device='cuda:0') and h-range 1.18-0.81: 0.006499128881841898\n",
      "Epoch 0 iter 77 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.77: 0.006369156762957573\n",
      "Epoch 0 iter 78 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.0063009909354150295\n",
      "Epoch 0 iter 79 - Loss for system size tensor([4], device='cuda:0') and h-range 1.26-0.8: 0.006178718060255051\n",
      "Epoch 0 iter 80 - Loss for system size tensor([4], device='cuda:0') and h-range 1.23-0.8: 0.006203864701092243\n",
      "Epoch 0 iter 81 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.8: 0.006104788277298212\n",
      "Epoch 0 iter 82 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.0059800539165735245\n",
      "Epoch 0 iter 83 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.81: 0.005926693789660931\n",
      "Epoch 0 iter 84 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.81: 0.005814090836793184\n",
      "Epoch 0 iter 85 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.0057611665688455105\n",
      "Epoch 0 iter 86 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.8: 0.005708430428057909\n",
      "Epoch 0 iter 87 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.8: 0.005665123462677002\n",
      "Epoch 0 iter 88 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.79: 0.005613234359771013\n",
      "Epoch 0 iter 89 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.8: 0.005548829212784767\n",
      "Epoch 0 iter 90 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.79: 0.0054323491640388966\n",
      "Epoch 0 iter 91 - Loss for system size tensor([4], device='cuda:0') and h-range 1.22-0.78: 0.005444447975605726\n",
      "Epoch 0 iter 92 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.78: 0.005336255766451359\n",
      "Epoch 0 iter 93 - Loss for system size tensor([4], device='cuda:0') and h-range 1.19-0.76: 0.005253440234810114\n",
      "Epoch 0 iter 94 - Loss for system size tensor([4], device='cuda:0') and h-range 1.21-0.82: 0.005232164636254311\n",
      "Epoch 0 iter 95 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.78: 0.005161532666534185\n",
      "Epoch 0 iter 96 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.005124340765178204\n",
      "Epoch 0 iter 97 - Loss for system size tensor([4], device='cuda:0') and h-range 1.24-0.81: 0.005072849802672863\n",
      "Epoch 0 iter 98 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.8: 0.005032233893871307\n",
      "Epoch 0 iter 99 - Loss for system size tensor([4], device='cuda:0') and h-range 1.2-0.81: 0.004971313755959272\n",
      "Hamiltonian for size tensor([4], device='cuda:0') took 15.186730861663818 seconds\n"
     ]
    }
   ],
   "source": [
    "opt.train(epochs=1, start_iter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonians[0].training_dataset.sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x, y, z) = (101, 1, 16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           2,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           4,
           0,
           0,
           0,
           1,
           2,
           1,
           0,
           2,
           0,
           1,
           4,
           1,
           2,
           0,
           1,
           0,
           4,
           4,
           2,
           3,
           2,
           1,
           3,
           2,
           3,
           2,
           3,
           5,
           4,
           8,
           3,
           4,
           3,
           3,
           5,
           7,
           3,
           5,
           2,
           2,
           3,
           4,
           9,
           8,
           13,
           11,
           6,
           3,
           8,
           9,
           11,
           6,
           9,
           7,
           14,
           9,
           9,
           11,
           21,
           23,
           19,
           22,
           22,
           12,
           23,
           20,
           20,
           17,
           24,
           22,
           23,
           26,
           24,
           23,
           42,
           34,
           32,
           35,
           37,
           45,
           39,
           33,
           28,
           27,
           39,
           48,
           37,
           31,
           30,
           38,
           58,
           63,
           58,
           56,
           69,
           60,
           54,
           67,
           49,
           56,
           66,
           64,
           57,
           51,
           62,
           49,
           78,
           73,
           80,
           80,
           83,
           82,
           82,
           77,
           82,
           88,
           79,
           83,
           79,
           86,
           88,
           81,
           98,
           95,
           97,
           96,
           97,
           96,
           98,
           97,
           99,
           95,
           97,
           93,
           98,
           98,
           97,
           95,
           100,
           99,
           99,
           100,
           100,
           99,
           97,
           100,
           98,
           100,
           100,
           99,
           100,
           100,
           100,
           97,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           99,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           99,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           100,
           99,
           100,
           100,
           100,
           100,
           99,
           99,
           99,
           98,
           100,
           100,
           93,
           93,
           96,
           98,
           94,
           95,
           92,
           93,
           93,
           93,
           94,
           96,
           97,
           99,
           94,
           96,
           78,
           89,
           83,
           85,
           82,
           80,
           78,
           78,
           81,
           74,
           85,
           83,
           78,
           79,
           84,
           82,
           50,
           63,
           65,
           64,
           61,
           58,
           67,
           57,
           60,
           60,
           55,
           60,
           60,
           61,
           60,
           61,
           36,
           46,
           41,
           44,
           28,
           37,
           35,
           40,
           38,
           42,
           38,
           33,
           25,
           36,
           32,
           32,
           28,
           21,
           20,
           18,
           19,
           30,
           19,
           20,
           20,
           19,
           18,
           27,
           22,
           23,
           21,
           22,
           11,
           13,
           6,
           14,
           7,
           12,
           10,
           7,
           9,
           9,
           9,
           11,
           10,
           8,
           10,
           11,
           8,
           2,
           2,
           5,
           6,
           4,
           5,
           6,
           9,
           4,
           3,
           4,
           7,
           8,
           6,
           3,
           3,
           4,
           2,
           5,
           2,
           2,
           1,
           3,
           2,
           1,
           2,
           3,
           4,
           7,
           1,
           4,
           1,
           1,
           1,
           1,
           1,
           2,
           2,
           0,
           2,
           0,
           0,
           0,
           1,
           0,
           2,
           4,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          "colorscale": [
           [
            0,
            "rgb(247,252,253)"
           ],
           [
            0.125,
            "rgb(224,236,244)"
           ],
           [
            0.25,
            "rgb(191,211,230)"
           ],
           [
            0.375,
            "rgb(158,188,218)"
           ],
           [
            0.5,
            "rgb(140,150,198)"
           ],
           [
            0.625,
            "rgb(140,107,177)"
           ],
           [
            0.75,
            "rgb(136,65,157)"
           ],
           [
            0.875,
            "rgb(129,15,124)"
           ],
           [
            1,
            "rgb(77,0,75)"
           ]
          ],
          "opacity": 0.5,
          "size": 3
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          32,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          36,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          45,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          81,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          82,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          83,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          85,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          86,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          87,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          88,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          89,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          90,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          91,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          92,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          93,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          94,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          95,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          96,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          97,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          98,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          99,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "z": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ]
        }
       ],
       "layout": {
        "scene": {
         "xaxis": {
          "title": {
           "text": "batch"
          }
         },
         "yaxis": {
          "title": {
           "text": "system size"
          }
         },
         "zaxis": {
          "title": {
           "text": "parameter"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tensor(\n",
    "    Hamiltonians[0].training_dataset.sampled.unsqueeze(1).cpu().numpy(),\n",
    "    [\"batch\", \"system size\", \"parameter\"],\n",
    "    opacity=0.5,\n",
    "    size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Non-Batched Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m point_of_interest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m use_SR \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m Hamiltonians \u001b[38;5;241m=\u001b[39m [Ising(L) \u001b[38;5;28;01mfor\u001b[39;00m L \u001b[38;5;129;01min\u001b[39;00m system_sizes]\n\u001b[1;32m     15\u001b[0m data_dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFIM_ground_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-07-24T19-26-39.836\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ham \u001b[38;5;129;01min\u001b[39;00m Hamiltonians:\n",
      "File \u001b[0;32m~/Projects/tqs/Ising.py:53\u001b[0m, in \u001b[0;36mIsing.__init__\u001b[0;34m(self, system_size, periodic)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexternal_field \u001b[38;5;241m=\u001b[39m generate_spin_idx(\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_size\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexternal_field\u001b[39m\u001b[38;5;124m\"\u001b[39m, periodic\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mH \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZZ\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnections),\n\u001b[1;32m     50\u001b[0m     ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexternal_field),\n\u001b[1;32m     51\u001b[0m ]\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_basis()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# TODO: implement 2D symmetry\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/Ising.py:107\u001b[0m, in \u001b[0;36mIsing.get_basis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m basis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn):\n\u001b[0;32m--> 107\u001b[0m     basis[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mint\u001b[39m(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mbinary_repr(i, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)])\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(basis\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/numpy/core/numeric.py:2027\u001b[0m, in \u001b[0;36mbinary_repr\u001b[0;34m(num, width)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     binwidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(binary)\n\u001b[1;32m   2025\u001b[0m     outwidth \u001b[38;5;241m=\u001b[39m (binwidth \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m builtins\u001b[38;5;241m.\u001b[39mmax(binwidth, width))\n\u001b[0;32m-> 2027\u001b[0m     warn_if_insufficient(width, binwidth)\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary\u001b[38;5;241m.\u001b[39mzfill(outwidth)\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/numpy/core/numeric.py:2009\u001b[0m, in \u001b[0;36mbinary_repr.<locals>.warn_if_insufficient\u001b[0;34m(width, binwidth)\u001b[0m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarn_if_insufficient\u001b[39m(width, binwidth):\n\u001b[0;32m-> 2009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m width \u001b[38;5;241m<\u001b[39m binwidth:\n\u001b[1;32m   2010\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2011\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient bit width provided. This behavior \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2012\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill raise an error in the future.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   2013\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "system_sizes = torch.arange(2, 16 + 1, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]\n",
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 1000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False\n",
    "\n",
    "Hamiltonians = [Ising(L) for L in system_sizes]\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-07-24T19-26-39.836\")\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(data_dir_path)\n",
    "\n",
    "print(\"Sizes:\\n\", system_sizes)\n",
    "print(\"Hamiltonians:\", Hamiltonians)\n",
    "print(\"Dimensions of parameter space:\", param_dim)\n",
    "print(\"Number of units in a feedforward layer:\", n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")\n",
    "\n",
    "results_dir = \"results\"\n",
    "paper_checkpoint_name = \"ckpt_100000_Ising_32_8_8_0.ckpt\"\n",
    "paper_checkpoint_path = os.path.join(results_dir, paper_checkpoint_name)\n",
    "checkpoint = torch.load(paper_checkpoint_path)\n",
    "testmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): TQSPositionalEncoding1D(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_Q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_K): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_V): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (amp_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (phase_head): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/Projects/tqs/model.py:228: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m opt\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, start_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised_batches.py:304\u001b[0m, in \u001b[0;36mOptimizer.train\u001b[0;34m(self, epochs, param_range, ensemble_id, start_iter)\u001b[0m\n\u001b[1;32m    300\u001b[0m dataset \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39mtraining_dataset\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m basis_states, params, psi_true \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mset_param(system_size\u001b[38;5;241m=\u001b[39msystem_size, param\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    305\u001b[0m     log_amp, log_phase \u001b[38;5;241m=\u001b[39m compute_psi(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    307\u001b[0m         basis_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,  \u001b[38;5;66;03m# NOTE: setting this puts compute_psi in to the new cross-J batch mode\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    313\u001b[0m     psi_predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpsi_from_logs(log_amp, log_phase)\n",
      "File \u001b[0;32m~/Projects/tqs/model.py:151\u001b[0m, in \u001b[0;36mTransformerModel.set_param\u001b[0;34m(self, system_size, param)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_range[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dim) \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_range[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_range[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;241m=\u001b[39m param\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "param_range = torch.tensor([[0.5, 1.5]])\n",
    "param_step = torch.tensor([0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.minibatch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([2], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([4], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([6], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([8], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([10], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([12], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([14], device='cuda:0') spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([16], device='cuda:0') spins at point (0.5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/Projects/tqs/model.py:228: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# with cProfile.Profile() as pr:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# with torch.autograd.profiler.profile(use_cuda=True) as prof:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m opt\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39mepochs, param_range\u001b[38;5;241m=\u001b[39mparam_range, param_step\u001b[38;5;241m=\u001b[39mparam_step, start_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised.py:315\u001b[0m, in \u001b[0;36mOptimizer.train\u001b[0;34m(self, epochs, param_range, param_step, ensemble_id, start_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# NOTE: the system size is constant for this inner loop but must be reset\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# here because leaving it out (or, equivalently, setting it to None) would\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# cause the model to sample a random system size. See set_param in model.py.\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m dummy_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(H\u001b[38;5;241m.\u001b[39mbasis, compute_phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRan forward for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m spins at point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# loss = self.calculate_mse_step(\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#     H, param, basis_batch=None, use_symmetry=True\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/model.py:309\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, spins, compute_phase)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# src_i = src_i + self.pos_embedding[:len(src_i)]  # (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    308\u001b[0m src_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src_i, system_size)  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m output_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(\n\u001b[1;32m    310\u001b[0m     src_i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_mask\n\u001b[1;32m    311\u001b[0m )  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    312\u001b[0m psi_output \u001b[38;5;241m=\u001b[39m output_i[\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_prefix_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[1;32m    314\u001b[0m ]  \u001b[38;5;66;03m# only use the physical degrees of freedom\u001b[39;00m\n\u001b[1;32m    315\u001b[0m amp_i \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp_head(psi_output), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    317\u001b[0m )  \u001b[38;5;66;03m# (seq, batch, phys_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask, is_causal\u001b[38;5;241m=\u001b[39mis_causal, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:119\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:128\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: Tensor, attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    129\u001b[0m         x,\n\u001b[1;32m    130\u001b[0m         x,\n\u001b[1;32m    131\u001b[0m         x,\n\u001b[1;32m    132\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    133\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    134\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:142\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     87\u001b[0m             query: Tensor,\n\u001b[1;32m     88\u001b[0m             key: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m             attn_mask: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m             average_attn_weights: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Optional[Tensor]]:\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mNote::\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m      head of shape :math:`(N, num_heads, L, S)`.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(query, key, value, key_padding_mask,\n\u001b[1;32m    143\u001b[0m                               need_weights, attn_mask, average_attn_weights)\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:259\u001b[0m, in \u001b[0;36mMultiheadAttention._forward_impl\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m         key_padding_mask \u001b[38;5;241m=\u001b[39m nnF\u001b[38;5;241m.\u001b[39mpad(key_padding_mask, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 259\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(attn_output_weights\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m [bsz \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, src_len]\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "# with cProfile.Profile() as pr:\n",
    "# with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "opt.train(epochs=epochs, param_range=param_range, param_step=param_step, start_iter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
