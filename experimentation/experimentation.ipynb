{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1))"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 1000\n",
    "torch.tensor([batch], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02, 4.0343e+02,\n",
       "        1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04])"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.float32)\n",
    "logs.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `samples` tensor after applying symmetry and reshaping:\n",
      "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
      "        [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
      "        [ 8,  9, 10, 11, 20, 21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initial dimensions\n",
    "n_symm = 2\n",
    "n = 3\n",
    "batch0 = 4\n",
    "\n",
    "# Create a tensor representing samples before symmetry and reshaping\n",
    "# For simplicity, let's fill it with integers to easily track transformations\n",
    "samples_initial = torch.arange(n_symm * n * batch0).reshape(n_symm, n, batch0)\n",
    "\n",
    "\n",
    "# Apply a dummy symmetry operation (for the sake of example, let's just return the tensor as is)\n",
    "def symmetry(samples):\n",
    "    # In a real scenario, this function would apply some symmetry transformation\n",
    "    return samples, torch.zeros((n_symm, batch0))  # Returning a dummy phase tensor\n",
    "\n",
    "\n",
    "samples, phase = symmetry(samples_initial)\n",
    "\n",
    "# Reshape according to the code snippet\n",
    "samples = samples.transpose(0, 1).reshape(n, -1)  # (n, n_symm*batch0)\n",
    "\n",
    "print(\"Example `samples` tensor after applying symmetry and reshaping:\")\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/scratchgpt/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "encoder_layers = TransformerEncoderLayer(embedding_size, n_head, n_hid, dropout)\n",
    "transformer_encoder = TransformerEncoder(encoder_layers, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder_input = torch.randn(minibatch, 10, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Does sample() Do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.binomial import Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 10\n",
      "samples: tensor([], size=(0, 1))\n",
      "sample_count: tensor([10])\n"
     ]
    }
   ],
   "source": [
    "batch = 10\n",
    "samples = torch.zeros(0, 1)\n",
    "sample_count = torch.tensor([batch], dtype=torch.int64)\n",
    "probs = torch.tensor([0.5], dtype=torch.float32)  # P(s_1  | J) = 0.5\n",
    "\n",
    "print(\"batch:\", batch)\n",
    "print(\"samples:\", samples)\n",
    "print(\"sample_count:\", sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_count before mask:\n",
      " tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 3.])\n",
      "samples before mask:\n",
      " tensor([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "samples to mask away:\n",
      " tensor([[0., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "distribution = Binomial(total_count=sample_count, probs=probs)\n",
    "zero_count = distribution.sample()\n",
    "one_count = sample_count - zero_count\n",
    "sample_count = torch.cat((zero_count, one_count), dim=0)\n",
    "print(\"sample_count before mask:\\n\", sample_count)\n",
    "mask = sample_count > 0\n",
    "reverse_mask = ~mask\n",
    "batch = samples.shape[1]\n",
    "samples = torch.cat(\n",
    "    [\n",
    "        torch.cat([samples, torch.zeros(1, batch)], dim=0),\n",
    "        torch.cat([samples, torch.ones(1, batch)], dim=0),\n",
    "    ],\n",
    "    dim=1,\n",
    ")\n",
    "print(\"samples before mask:\\n\", samples)\n",
    "masked_samples = samples.T[mask].T\n",
    "print(\"samples to mask away:\\n\", samples.T[reverse_mask].T)\n",
    "samples = samples.T[mask].T\n",
    "sample_count = sample_count[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Columns are sampled sequences. sample() will first generate\n",
    "these, ensuring they are unique. \n",
    "- It uses a probability \n",
    "distribution to sample, but does not use the probability distribution in the construction of the unique sequences.\n",
    "- The information about the sampled spins from the probability distribution is stored in sample_count, which is returned from sample()\n",
    "- samples is also returned from sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        False,  True, False, False, False,  True])"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is whether the zero or one addition is actually possible.\n",
    "# If not, we eliminate the whole row.\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 3.])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean masks:\n",
    "example = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.float32)\n",
    "example_mask = example > 5\n",
    "example[example_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [12],\n",
       "       [14],\n",
       "       [16],\n",
       "       [18],\n",
       "       [20],\n",
       "       [22],\n",
       "       [24],\n",
       "       [26],\n",
       "       [28],\n",
       "       [30],\n",
       "       [32],\n",
       "       [34],\n",
       "       [36],\n",
       "       [38],\n",
       "       [40]])"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes = np.arange(10, 41, 2).reshape(-1, 1)\n",
    "system_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Input tensor\n",
    "x = torch.tensor([1.0, 2.0, -3.0])\n",
    "\n",
    "# Compute softmax\n",
    "softmax = torch.softmax(torch.tensor([1.0, 2.0, 3.0]), dim=0)\n",
    "\n",
    "# Print the result\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.6028e-09, 1.0000e+00, 1.0262e-10])\n",
      "tensor([0.0086, 0.9883, 0.0031])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.softmax(torch.tensor([1.0, 20.0, -3.0]), dim=0))\n",
    "print(torch.softmax(torch.tensor([1.0, 20.0, -3.0]) / 4, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratchgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
