{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from optimizer_supervised import Optimizer\n",
    "from Ising import Ising\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup():\n",
    "    # Setup for PyTorch:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        print(\"PyTorch is using GPU {}\".format(torch.cuda.current_device()))\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "        print(\"GPU unavailable; using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpu_setup()\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 8],\n",
       "        [10],\n",
       "        [12],\n",
       "        [14],\n",
       "        [16],\n",
       "        [18],\n",
       "        [20]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes = torch.arange(2, 21, 2, device=\"cpu\").reshape(-1, 1)\n",
    "system_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 1000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Small allocation for model parameters, layers, etc.\n",
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): TQSPositionalEncoding1D(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_Q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_K): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_V): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (amp_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (phase_head): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following .forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16])\n"
     ]
    }
   ],
   "source": [
    "H = Hamiltonians[7]\n",
    "print(H.system_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "spins = H.basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 1,  ..., 0, 1, 1],\n",
       "        [0, 1, 0,  ..., 1, 0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 65536])\n"
     ]
    }
   ],
   "source": [
    "symmetry = H.symmetry\n",
    "spins_reduced, phases_reduced = symmetry(spins)\n",
    "print(spins_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spins_reduced[0] == spins).sum() - (spins.shape[0] * spins.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 16 65536\n"
     ]
    }
   ],
   "source": [
    "n_symm, n, batch0 = spins_reduced.shape\n",
    "print(n_symm, n, batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 262144])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spins_all = spins_reduced.transpose(0, 1).reshape(n, -1)\n",
    "spins_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(262144)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2**H.n) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.set_param(system_size=H.system_size, param=torch.tensor([1.0], device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.7665, -0.6248],\n",
       "          [-0.7665, -0.6248],\n",
       "          [-0.7665, -0.6248],\n",
       "          ...,\n",
       "          [-0.7665, -0.6248],\n",
       "          [-0.7665, -0.6248],\n",
       "          [-0.7665, -0.6248]],\n",
       " \n",
       "         [[-0.6480, -0.7404],\n",
       "          [-0.6480, -0.7404],\n",
       "          [-0.6480, -0.7404],\n",
       "          ...,\n",
       "          [-0.6752, -0.7114],\n",
       "          [-0.6752, -0.7114],\n",
       "          [-0.6752, -0.7114]],\n",
       " \n",
       "         [[-0.6914, -0.6949],\n",
       "          [-0.6914, -0.6949],\n",
       "          [-0.6914, -0.6949],\n",
       "          ...,\n",
       "          [-0.6938, -0.6925],\n",
       "          [-0.6938, -0.6925],\n",
       "          [-0.6938, -0.6925]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.6782, -0.7083],\n",
       "          [-0.6782, -0.7083],\n",
       "          [-0.6782, -0.7083],\n",
       "          ...,\n",
       "          [-0.6175, -0.7750],\n",
       "          [-0.6175, -0.7750],\n",
       "          [-0.6175, -0.7750]],\n",
       " \n",
       "         [[-0.6869, -0.6994],\n",
       "          [-0.6869, -0.6994],\n",
       "          [-0.6895, -0.6968],\n",
       "          ...,\n",
       "          [-0.6356, -0.7542],\n",
       "          [-0.6254, -0.7658],\n",
       "          [-0.6254, -0.7658]],\n",
       " \n",
       "         [[-0.6874, -0.6989],\n",
       "          [-0.6911, -0.6952],\n",
       "          [-0.6856, -0.7007],\n",
       "          ...,\n",
       "          [-0.6294, -0.7612],\n",
       "          [-0.6347, -0.7552],\n",
       "          [-0.6265, -0.7646]]], device='cuda:0', grad_fn=<CatBackward0>),\n",
       " tensor([[[4.3254, 5.6055],\n",
       "          [4.3254, 5.6055],\n",
       "          [4.3254, 5.6055],\n",
       "          ...,\n",
       "          [4.3254, 5.6055],\n",
       "          [4.3254, 5.6055],\n",
       "          [4.3254, 5.6055]],\n",
       " \n",
       "         [[3.5224, 3.9144],\n",
       "          [3.5224, 3.9144],\n",
       "          [3.5224, 3.9144],\n",
       "          ...,\n",
       "          [3.4686, 4.3053],\n",
       "          [3.4686, 4.3053],\n",
       "          [3.4686, 4.3053]],\n",
       " \n",
       "         [[3.5552, 3.6365],\n",
       "          [3.5552, 3.6365],\n",
       "          [3.5552, 3.6365],\n",
       "          ...,\n",
       "          [3.3657, 3.6042],\n",
       "          [3.3657, 3.6042],\n",
       "          [3.3657, 3.6042]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.6841, 3.5204],\n",
       "          [3.6841, 3.5204],\n",
       "          [3.6841, 3.5204],\n",
       "          ...,\n",
       "          [3.5779, 3.5297],\n",
       "          [3.5779, 3.5297],\n",
       "          [3.5779, 3.5297]],\n",
       " \n",
       "         [[3.6708, 3.5158],\n",
       "          [3.6708, 3.5158],\n",
       "          [3.6605, 3.4599],\n",
       "          ...,\n",
       "          [3.6181, 3.6849],\n",
       "          [3.5782, 3.5818],\n",
       "          [3.5782, 3.5818]],\n",
       " \n",
       "         [[3.6677, 3.4892],\n",
       "          [3.6581, 3.4228],\n",
       "          [3.6628, 3.4938],\n",
       "          ...,\n",
       "          [3.5691, 3.4986],\n",
       "          [3.6020, 3.6212],\n",
       "          [3.5634, 3.5119]]], device='cuda:0', grad_fn=<CatBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = testmodel.forward(spins)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src \u001b[38;5;241m=\u001b[39m testmodel\u001b[38;5;241m.\u001b[39mwrap_spins(spins)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testmodel' is not defined"
     ]
    }
   ],
   "source": [
    "src = testmodel.wrap_spins(spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.src_mask = testmodel._generate_square_subsequent_mask(src.size(0)).to(\n",
    "    src.device\n",
    ")\n",
    "testmodel.src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7726], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = src[\n",
    "    : testmodel.n_dim, 0, testmodel.phys_dim : testmodel.phys_dim + testmodel.n_dim\n",
    "].diag()\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = system_size.exp().round().to(torch.int64)\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         ...,\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698]],\n",
       "\n",
       "        [[-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         ...,\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         ...,\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.encoder(src) * math.sqrt(testmodel.embedding_size)\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a problem if GPU memory usage increases at this point; this operation should be in-place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         ...,\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660]],\n",
       "\n",
       "        [[-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         ...,\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544]],\n",
       "\n",
       "        [[ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         [ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         [ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         ...,\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933],\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933],\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         [ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         [ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         ...,\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933],\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933],\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933]],\n",
       "\n",
       "        [[ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933],\n",
       "         ...,\n",
       "         [ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933]],\n",
       "\n",
       "        [[ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933],\n",
       "         [ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         ...,\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933],\n",
       "         [ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.pos_encoder(src)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         ...,\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149]],\n",
       "\n",
       "        [[ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         ...,\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868]],\n",
       "\n",
       "        [[ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         [ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         [ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         ...,\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962],\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962],\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         [-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         [-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         ...,\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132],\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132],\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132]],\n",
       "\n",
       "        [[-0.2757, -1.3132, -0.3750,  ..., -0.3658, -0.2897,  1.2813],\n",
       "         [-0.2757, -1.3132, -0.3750,  ..., -0.3658, -0.2897,  1.2813],\n",
       "         [-0.4871, -1.6481, -0.0597,  ..., -0.1524, -0.1294,  0.8363],\n",
       "         ...,\n",
       "         [-0.0593, -1.1778, -0.5836,  ..., -0.5776, -0.3883,  0.6502],\n",
       "         [-0.1138, -1.3405, -0.4261,  ..., -0.4941, -0.3199,  0.4176],\n",
       "         [-0.1138, -1.3405, -0.4261,  ..., -0.4941, -0.3199,  0.4176]],\n",
       "\n",
       "        [[-0.3291, -1.4244, -0.3467,  ..., -0.3208, -0.2922,  1.2279],\n",
       "         [-0.5741, -1.7603, -0.0492,  ..., -0.1247, -0.1376,  0.8103],\n",
       "         [-0.3373, -1.4102, -0.3645,  ..., -0.3412, -0.2937,  1.2181],\n",
       "         ...,\n",
       "         [-0.1875, -1.3956, -0.4357,  ..., -0.4924, -0.3626,  0.4625],\n",
       "         [-0.1227, -1.2308, -0.5920,  ..., -0.5779, -0.4126,  0.6528],\n",
       "         [-0.1790, -1.3914, -0.4386,  ..., -0.5024, -0.3532,  0.4388]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = testmodel.transformer_encoder(src, testmodel.src_mask)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
