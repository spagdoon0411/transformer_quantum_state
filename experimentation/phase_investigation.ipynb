{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from hamiltonians.Ising import Ising\n",
    "from model.model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup():\n",
    "    # Setup for PyTorch:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        print(\"PyTorch is using GPU {}\".format(torch.cuda.current_device()))\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "        print(\"GPU unavailable; using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpu_setup()\n",
    "torch.set_default_device(\"cuda\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: h values in metadata file do not match Hamiltonian's param_range; found h_min=0, h_max=2, h_step=0.1, expected h_min=0.5, h_max=1.5. Setting param_range to match.\n",
      "Loaded dataset for system size 8 from TFIM_ground_states/2024-08-02T20-42-27.916/8.arrow.\n",
      "(h_min, h_step, h_max) = (0, 0.1, 2).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/aten/src/ATen/native/TensorShape.cpp:3675.)\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "system_sizes = torch.arange(8, 8 + 2, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True, get_basis=True) for size in system_sizes]\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-08-02T20-42-27.916\")\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(\n",
    "        data_dir_path,\n",
    "        batch_size=1024,\n",
    "        samples_in_epoch=100,\n",
    "        sampling_type=\"shuffled\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 10000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False\n",
    "\n",
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()\n",
    "\n",
    "results_dir = \"results\"\n",
    "paper_checkpoint_name = \"ckpt_100000_Ising_32_8_8_0.ckpt\"\n",
    "paper_checkpoint_path = os.path.join(results_dir, paper_checkpoint_name)\n",
    "checkpoint = torch.load(paper_checkpoint_path)\n",
    "testmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = Hamiltonians[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ham.training_dataset\n",
    "sampler = ham.sampler\n",
    "for idx in sampler:\n",
    "    basis, params, psi_true = dataset[idx]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1,  ..., 0, 1, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 1, 1],\n",
       "        ...,\n",
       "        [1, 0, 1,  ..., 0, 0, 1],\n",
       "        [0, 1, 0,  ..., 0, 0, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [1.4000],\n",
       "        [1.8000],\n",
       "        ...,\n",
       "        [1.4000],\n",
       "        [1.6000],\n",
       "        [0.7000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0027,  0.0232,  0.0545,  ...,  0.1153, -0.0271, -0.0062],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfull = ham.full_H(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 2164 stored elements and shape (256, 256)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham.update_param(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = eigsh(hfull, k=1, which=\"SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy, psi_dataset = ham.retrieve_ground(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = vecs[:, 0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.tensor(psi) - psi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2584, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4591, -0.1292, -0.1292, -0.0774, -0.1292, -0.0404, -0.0774, -0.0607,\n",
      "        -0.1292, -0.0378, -0.0404, -0.0274, -0.0774, -0.0274, -0.0607, -0.0564,\n",
      "        -0.1292, -0.0375, -0.0378, -0.0246, -0.0404, -0.0137, -0.0274, -0.0247,\n",
      "        -0.0774, -0.0246, -0.0274, -0.0221, -0.0607, -0.0247, -0.0564, -0.0607,\n",
      "        -0.1292, -0.0378, -0.0375, -0.0246, -0.0378, -0.0128, -0.0246, -0.0221,\n",
      "        -0.0404, -0.0128, -0.0137, -0.0110, -0.0274, -0.0113, -0.0247, -0.0274,\n",
      "        -0.0774, -0.0246, -0.0246, -0.0192, -0.0274, -0.0110, -0.0221, -0.0246,\n",
      "        -0.0607, -0.0221, -0.0247, -0.0246, -0.0564, -0.0274, -0.0607, -0.0774,\n",
      "        -0.1292, -0.0404, -0.0378, -0.0274, -0.0375, -0.0137, -0.0246, -0.0247,\n",
      "        -0.0378, -0.0128, -0.0128, -0.0113, -0.0246, -0.0110, -0.0221, -0.0274,\n",
      "        -0.0404, -0.0137, -0.0128, -0.0110, -0.0137, -0.0060, -0.0110, -0.0137,\n",
      "        -0.0274, -0.0110, -0.0113, -0.0128, -0.0247, -0.0137, -0.0274, -0.0404,\n",
      "        -0.0774, -0.0274, -0.0246, -0.0221, -0.0246, -0.0110, -0.0192, -0.0246,\n",
      "        -0.0274, -0.0113, -0.0110, -0.0128, -0.0221, -0.0128, -0.0246, -0.0378,\n",
      "        -0.0607, -0.0247, -0.0221, -0.0246, -0.0247, -0.0137, -0.0246, -0.0375,\n",
      "        -0.0564, -0.0274, -0.0274, -0.0378, -0.0607, -0.0404, -0.0774, -0.1292,\n",
      "        -0.1292, -0.0774, -0.0404, -0.0607, -0.0378, -0.0274, -0.0274, -0.0564,\n",
      "        -0.0375, -0.0246, -0.0137, -0.0247, -0.0246, -0.0221, -0.0247, -0.0607,\n",
      "        -0.0378, -0.0246, -0.0128, -0.0221, -0.0128, -0.0110, -0.0113, -0.0274,\n",
      "        -0.0246, -0.0192, -0.0110, -0.0246, -0.0221, -0.0246, -0.0274, -0.0774,\n",
      "        -0.0404, -0.0274, -0.0137, -0.0247, -0.0128, -0.0113, -0.0110, -0.0274,\n",
      "        -0.0137, -0.0110, -0.0060, -0.0137, -0.0110, -0.0128, -0.0137, -0.0404,\n",
      "        -0.0274, -0.0221, -0.0110, -0.0246, -0.0113, -0.0128, -0.0128, -0.0378,\n",
      "        -0.0247, -0.0246, -0.0137, -0.0375, -0.0274, -0.0378, -0.0404, -0.1292,\n",
      "        -0.0774, -0.0607, -0.0274, -0.0564, -0.0246, -0.0247, -0.0221, -0.0607,\n",
      "        -0.0246, -0.0221, -0.0110, -0.0274, -0.0192, -0.0246, -0.0246, -0.0774,\n",
      "        -0.0274, -0.0247, -0.0113, -0.0274, -0.0110, -0.0137, -0.0128, -0.0404,\n",
      "        -0.0221, -0.0246, -0.0128, -0.0378, -0.0246, -0.0375, -0.0378, -0.1292,\n",
      "        -0.0607, -0.0564, -0.0247, -0.0607, -0.0221, -0.0274, -0.0246, -0.0774,\n",
      "        -0.0247, -0.0274, -0.0137, -0.0404, -0.0246, -0.0378, -0.0375, -0.1292,\n",
      "        -0.0564, -0.0607, -0.0274, -0.0774, -0.0274, -0.0404, -0.0378, -0.1292,\n",
      "        -0.0607, -0.0774, -0.0404, -0.1292, -0.0774, -0.1292, -0.1292, -0.4591],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(psi_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4591,  0.1292,  0.1292, -0.0774,  0.1292, -0.0404, -0.0774,  0.0607,\n",
      "         0.1292, -0.0378, -0.0404,  0.0274, -0.0774,  0.0274,  0.0607, -0.0564,\n",
      "         0.1292, -0.0375, -0.0378,  0.0246, -0.0404,  0.0137,  0.0274, -0.0247,\n",
      "        -0.0774,  0.0246,  0.0274, -0.0221,  0.0607, -0.0247, -0.0564,  0.0607,\n",
      "         0.1292, -0.0378, -0.0375,  0.0246, -0.0378,  0.0128,  0.0246, -0.0221,\n",
      "        -0.0404,  0.0128,  0.0137, -0.0110,  0.0274, -0.0113, -0.0247,  0.0274,\n",
      "        -0.0774,  0.0246,  0.0246, -0.0192,  0.0274, -0.0110, -0.0221,  0.0246,\n",
      "         0.0607, -0.0221, -0.0247,  0.0246, -0.0564,  0.0274,  0.0607, -0.0774,\n",
      "         0.1292, -0.0404, -0.0378,  0.0274, -0.0375,  0.0137,  0.0246, -0.0247,\n",
      "        -0.0378,  0.0128,  0.0128, -0.0113,  0.0246, -0.0110, -0.0221,  0.0274,\n",
      "        -0.0404,  0.0137,  0.0128, -0.0110,  0.0137, -0.0060, -0.0110,  0.0137,\n",
      "         0.0274, -0.0110, -0.0113,  0.0128, -0.0247,  0.0137,  0.0274, -0.0404,\n",
      "        -0.0774,  0.0274,  0.0246, -0.0221,  0.0246, -0.0110, -0.0192,  0.0246,\n",
      "         0.0274, -0.0113, -0.0110,  0.0128, -0.0221,  0.0128,  0.0246, -0.0378,\n",
      "         0.0607, -0.0247, -0.0221,  0.0246, -0.0247,  0.0137,  0.0246, -0.0375,\n",
      "        -0.0564,  0.0274,  0.0274, -0.0378,  0.0607, -0.0404, -0.0774,  0.1292,\n",
      "         0.1292, -0.0774, -0.0404,  0.0607, -0.0378,  0.0274,  0.0274, -0.0564,\n",
      "        -0.0375,  0.0246,  0.0137, -0.0247,  0.0246, -0.0221, -0.0247,  0.0607,\n",
      "        -0.0378,  0.0246,  0.0128, -0.0221,  0.0128, -0.0110, -0.0113,  0.0274,\n",
      "         0.0246, -0.0192, -0.0110,  0.0246, -0.0221,  0.0246,  0.0274, -0.0774,\n",
      "        -0.0404,  0.0274,  0.0137, -0.0247,  0.0128, -0.0113, -0.0110,  0.0274,\n",
      "         0.0137, -0.0110, -0.0060,  0.0137, -0.0110,  0.0128,  0.0137, -0.0404,\n",
      "         0.0274, -0.0221, -0.0110,  0.0246, -0.0113,  0.0128,  0.0128, -0.0378,\n",
      "        -0.0247,  0.0246,  0.0137, -0.0375,  0.0274, -0.0378, -0.0404,  0.1292,\n",
      "        -0.0774,  0.0607,  0.0274, -0.0564,  0.0246, -0.0247, -0.0221,  0.0607,\n",
      "         0.0246, -0.0221, -0.0110,  0.0274, -0.0192,  0.0246,  0.0246, -0.0774,\n",
      "         0.0274, -0.0247, -0.0113,  0.0274, -0.0110,  0.0137,  0.0128, -0.0404,\n",
      "        -0.0221,  0.0246,  0.0128, -0.0378,  0.0246, -0.0375, -0.0378,  0.1292,\n",
      "         0.0607, -0.0564, -0.0247,  0.0607, -0.0221,  0.0274,  0.0246, -0.0774,\n",
      "        -0.0247,  0.0274,  0.0137, -0.0404,  0.0246, -0.0378, -0.0375,  0.1292,\n",
      "        -0.0564,  0.0607,  0.0274, -0.0774,  0.0274, -0.0404, -0.0378,  0.1292,\n",
      "         0.0607, -0.0774, -0.0404,  0.1292, -0.0774,  0.1292,  0.1292, -0.4591],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(psi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-8.,  1.,  1.,  0.],\n",
       "        [ 1., -4.,  0.,  1.],\n",
       "        [ 1.,  0., -4.,  1.],\n",
       "        [ 0.,  1.,  1., -4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfull[0:4, 0:4].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([[1.0]])\n",
    "system_size = torch.tensor([15])\n",
    "testmodel.set_param(system_size, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model_utils import compute_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs, log_phases = compute_psi(testmodel, ham.basis, ham.symmetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0448, -3.4559, -4.3917, -4.0036, -4.5463, -5.6334, -5.2093, -4.2599,\n",
       "        -4.5859, -5.8897, -6.6644, -6.0234, -5.4894, -6.2668, -5.5583, -4.3355,\n",
       "        -4.5859, -5.9480, -6.8449, -6.3382, -6.8510, -7.7849, -7.2551, -6.1323,\n",
       "        -5.5512, -6.7054, -7.3426, -6.4548, -5.8779, -6.4406, -5.6325, -4.2599,\n",
       "        -4.5463, -5.9327, -6.8557, -6.4024, -6.9684, -7.9767, -7.5084, -6.4548,\n",
       "        -6.8510, -8.0753, -8.7824, -7.9914, -7.4908, -8.1220, -7.3678, -6.0234,\n",
       "        -5.4894, -6.7809, -7.6168, -6.9498, -7.4908, -8.2456, -7.6213, -6.3382,\n",
       "        -5.8779, -6.9116, -7.4592, -6.4024, -5.8797, -6.3043, -5.4765, -4.0036,\n",
       "        -4.3917, -5.8165, -6.7240, -6.3043, -6.8557, -7.9128, -7.4549, -6.4406,\n",
       "        -6.8449, -8.1240, -8.8482, -8.1220, -7.6168, -8.3110, -7.5779, -6.2668,\n",
       "        -6.6644, -8.0057, -8.8482, -8.2456, -8.7824, -9.6125, -9.0210, -7.7849,\n",
       "        -7.3426, -8.4260, -8.9919, -7.9767, -7.4592, -7.9128, -7.0955, -5.6334,\n",
       "        -5.2093, -6.5941, -7.4549, -6.9116, -7.5084, -8.4260, -7.8853, -6.7054,\n",
       "        -7.2551, -8.4067, -9.0210, -8.0753, -7.6213, -8.1240, -7.3305, -5.8897,\n",
       "        -5.5583, -6.8114, -7.5779, -6.7809, -7.3678, -8.0057, -7.3305, -5.9480,\n",
       "        -5.6325, -6.5941, -7.0955, -5.9327, -5.4765, -5.8165, -4.9856, -3.4559,\n",
       "        -3.4559, -4.9856, -5.8165, -5.4765, -5.9327, -7.0955, -6.5941, -5.6325,\n",
       "        -5.9480, -7.3305, -8.0057, -7.3678, -6.7809, -7.5779, -6.8114, -5.5583,\n",
       "        -5.8897, -7.3305, -8.1240, -7.6213, -8.0753, -9.0210, -8.4067, -7.2551,\n",
       "        -6.7054, -7.8853, -8.4260, -7.5084, -6.9116, -7.4549, -6.5941, -5.2093,\n",
       "        -5.6334, -7.0955, -7.9128, -7.4592, -7.9767, -8.9919, -8.4260, -7.3426,\n",
       "        -7.7849, -9.0210, -9.6125, -8.7824, -8.2456, -8.8482, -8.0057, -6.6644,\n",
       "        -6.2668, -7.5779, -8.3110, -7.6168, -8.1220, -8.8482, -8.1240, -6.8449,\n",
       "        -6.4406, -7.4549, -7.9128, -6.8557, -6.3043, -6.7240, -5.8165, -4.3917,\n",
       "        -4.0036, -5.4765, -6.3043, -5.8797, -6.4024, -7.4592, -6.9116, -5.8779,\n",
       "        -6.3382, -7.6213, -8.2456, -7.4908, -6.9498, -7.6168, -6.7809, -5.4894,\n",
       "        -6.0234, -7.3678, -8.1220, -7.4908, -7.9914, -8.7824, -8.0753, -6.8510,\n",
       "        -6.4548, -7.5084, -7.9767, -6.9684, -6.4024, -6.8557, -5.9327, -4.5463,\n",
       "        -4.2599, -5.6325, -6.4406, -5.8779, -6.4548, -7.3426, -6.7054, -5.5512,\n",
       "        -6.1323, -7.2551, -7.7849, -6.8510, -6.3382, -6.8449, -5.9480, -4.5859,\n",
       "        -4.3355, -5.5583, -6.2668, -5.4894, -6.0234, -6.6644, -5.8897, -4.5859,\n",
       "        -4.2599, -5.2093, -5.6334, -4.5463, -4.0036, -4.3917, -3.4559, -2.0448],\n",
       "       device='cuda:0', grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.exp(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2941e-01, 3.1558e-02, 1.2379e-02, 1.8249e-02, 1.0606e-02, 3.5764e-03,\n",
       "        5.4654e-03, 1.4124e-02, 1.0195e-02, 2.7677e-03, 1.2755e-03, 2.4215e-03,\n",
       "        4.1301e-03, 1.8982e-03, 3.8555e-03, 1.3095e-02, 1.0195e-02, 2.6111e-03,\n",
       "        1.0648e-03, 1.7676e-03, 1.0584e-03, 4.1599e-04, 7.0654e-04, 2.1715e-03,\n",
       "        3.8828e-03, 1.2242e-03, 6.4734e-04, 1.5730e-03, 2.8006e-03, 1.5955e-03,\n",
       "        3.5797e-03, 1.4124e-02, 1.0606e-02, 2.6513e-03, 1.0535e-03, 1.6576e-03,\n",
       "        9.4114e-04, 3.4337e-04, 5.4848e-04, 1.5730e-03, 1.0584e-03, 3.1114e-04,\n",
       "        1.5342e-04, 3.3837e-04, 5.5821e-04, 2.9693e-04, 6.3124e-04, 2.4215e-03,\n",
       "        4.1301e-03, 1.1352e-03, 4.9211e-04, 9.5886e-04, 5.5821e-04, 2.6242e-04,\n",
       "        4.8992e-04, 1.7676e-03, 2.8006e-03, 9.9612e-04, 5.7614e-04, 1.6576e-03,\n",
       "        2.7957e-03, 1.8284e-03, 4.1840e-03, 1.8249e-02, 1.2379e-02, 2.9781e-03,\n",
       "        1.2017e-03, 1.8284e-03, 1.0535e-03, 3.6602e-04, 5.7860e-04, 1.5955e-03,\n",
       "        1.0648e-03, 2.9633e-04, 1.4364e-04, 2.9693e-04, 4.9211e-04, 2.4580e-04,\n",
       "        5.1165e-04, 1.8982e-03, 1.2755e-03, 3.3355e-04, 1.4364e-04, 2.6242e-04,\n",
       "        1.5342e-04, 6.6886e-05, 1.2084e-04, 4.1599e-04, 6.4734e-04, 2.1909e-04,\n",
       "        1.2441e-04, 3.4337e-04, 5.7614e-04, 3.6602e-04, 8.2886e-04, 3.5764e-03,\n",
       "        5.4654e-03, 1.3684e-03, 5.7860e-04, 9.9612e-04, 5.4848e-04, 2.1909e-04,\n",
       "        3.7625e-04, 1.2242e-03, 7.0654e-04, 2.2337e-04, 1.2084e-04, 3.1114e-04,\n",
       "        4.8992e-04, 2.9633e-04, 6.5523e-04, 2.7677e-03, 3.8555e-03, 1.1011e-03,\n",
       "        5.1165e-04, 1.1352e-03, 6.3124e-04, 3.3355e-04, 6.5523e-04, 2.6111e-03,\n",
       "        3.5797e-03, 1.3684e-03, 8.2886e-04, 2.6513e-03, 4.1840e-03, 2.9781e-03,\n",
       "        6.8359e-03, 3.1558e-02, 3.1558e-02, 6.8359e-03, 2.9781e-03, 4.1840e-03,\n",
       "        2.6513e-03, 8.2886e-04, 1.3684e-03, 3.5797e-03, 2.6111e-03, 6.5523e-04,\n",
       "        3.3355e-04, 6.3124e-04, 1.1352e-03, 5.1165e-04, 1.1011e-03, 3.8555e-03,\n",
       "        2.7677e-03, 6.5523e-04, 2.9633e-04, 4.8992e-04, 3.1114e-04, 1.2084e-04,\n",
       "        2.2337e-04, 7.0654e-04, 1.2242e-03, 3.7625e-04, 2.1909e-04, 5.4848e-04,\n",
       "        9.9612e-04, 5.7860e-04, 1.3684e-03, 5.4654e-03, 3.5764e-03, 8.2886e-04,\n",
       "        3.6602e-04, 5.7614e-04, 3.4337e-04, 1.2441e-04, 2.1909e-04, 6.4734e-04,\n",
       "        4.1599e-04, 1.2084e-04, 6.6886e-05, 1.5342e-04, 2.6242e-04, 1.4364e-04,\n",
       "        3.3355e-04, 1.2755e-03, 1.8982e-03, 5.1165e-04, 2.4580e-04, 4.9211e-04,\n",
       "        2.9693e-04, 1.4364e-04, 2.9633e-04, 1.0648e-03, 1.5955e-03, 5.7860e-04,\n",
       "        3.6602e-04, 1.0535e-03, 1.8284e-03, 1.2017e-03, 2.9781e-03, 1.2379e-02,\n",
       "        1.8249e-02, 4.1840e-03, 1.8284e-03, 2.7957e-03, 1.6576e-03, 5.7614e-04,\n",
       "        9.9612e-04, 2.8006e-03, 1.7676e-03, 4.8992e-04, 2.6242e-04, 5.5821e-04,\n",
       "        9.5886e-04, 4.9211e-04, 1.1352e-03, 4.1301e-03, 2.4215e-03, 6.3124e-04,\n",
       "        2.9693e-04, 5.5821e-04, 3.3837e-04, 1.5342e-04, 3.1114e-04, 1.0584e-03,\n",
       "        1.5730e-03, 5.4848e-04, 3.4337e-04, 9.4114e-04, 1.6576e-03, 1.0535e-03,\n",
       "        2.6513e-03, 1.0606e-02, 1.4124e-02, 3.5797e-03, 1.5955e-03, 2.8006e-03,\n",
       "        1.5730e-03, 6.4734e-04, 1.2242e-03, 3.8828e-03, 2.1715e-03, 7.0654e-04,\n",
       "        4.1599e-04, 1.0584e-03, 1.7676e-03, 1.0648e-03, 2.6111e-03, 1.0195e-02,\n",
       "        1.3095e-02, 3.8555e-03, 1.8982e-03, 4.1301e-03, 2.4215e-03, 1.2755e-03,\n",
       "        2.7677e-03, 1.0195e-02, 1.4124e-02, 5.4654e-03, 3.5764e-03, 1.0606e-02,\n",
       "        1.8249e-02, 1.2379e-02, 3.1558e-02, 1.2941e-01], device='cuda:0',\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "amps = torch.sqrt(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3597, 0.1776, 0.1113, 0.1351, 0.1030, 0.0598, 0.0739, 0.1188, 0.1010,\n",
       "        0.0526, 0.0357, 0.0492, 0.0643, 0.0436, 0.0621, 0.1144, 0.1010, 0.0511,\n",
       "        0.0326, 0.0420, 0.0325, 0.0204, 0.0266, 0.0466, 0.0623, 0.0350, 0.0254,\n",
       "        0.0397, 0.0529, 0.0399, 0.0598, 0.1188, 0.1030, 0.0515, 0.0325, 0.0407,\n",
       "        0.0307, 0.0185, 0.0234, 0.0397, 0.0325, 0.0176, 0.0124, 0.0184, 0.0236,\n",
       "        0.0172, 0.0251, 0.0492, 0.0643, 0.0337, 0.0222, 0.0310, 0.0236, 0.0162,\n",
       "        0.0221, 0.0420, 0.0529, 0.0316, 0.0240, 0.0407, 0.0529, 0.0428, 0.0647,\n",
       "        0.1351, 0.1113, 0.0546, 0.0347, 0.0428, 0.0325, 0.0191, 0.0241, 0.0399,\n",
       "        0.0326, 0.0172, 0.0120, 0.0172, 0.0222, 0.0157, 0.0226, 0.0436, 0.0357,\n",
       "        0.0183, 0.0120, 0.0162, 0.0124, 0.0082, 0.0110, 0.0204, 0.0254, 0.0148,\n",
       "        0.0112, 0.0185, 0.0240, 0.0191, 0.0288, 0.0598, 0.0739, 0.0370, 0.0241,\n",
       "        0.0316, 0.0234, 0.0148, 0.0194, 0.0350, 0.0266, 0.0149, 0.0110, 0.0176,\n",
       "        0.0221, 0.0172, 0.0256, 0.0526, 0.0621, 0.0332, 0.0226, 0.0337, 0.0251,\n",
       "        0.0183, 0.0256, 0.0511, 0.0598, 0.0370, 0.0288, 0.0515, 0.0647, 0.0546,\n",
       "        0.0827, 0.1776, 0.1776, 0.0827, 0.0546, 0.0647, 0.0515, 0.0288, 0.0370,\n",
       "        0.0598, 0.0511, 0.0256, 0.0183, 0.0251, 0.0337, 0.0226, 0.0332, 0.0621,\n",
       "        0.0526, 0.0256, 0.0172, 0.0221, 0.0176, 0.0110, 0.0149, 0.0266, 0.0350,\n",
       "        0.0194, 0.0148, 0.0234, 0.0316, 0.0241, 0.0370, 0.0739, 0.0598, 0.0288,\n",
       "        0.0191, 0.0240, 0.0185, 0.0112, 0.0148, 0.0254, 0.0204, 0.0110, 0.0082,\n",
       "        0.0124, 0.0162, 0.0120, 0.0183, 0.0357, 0.0436, 0.0226, 0.0157, 0.0222,\n",
       "        0.0172, 0.0120, 0.0172, 0.0326, 0.0399, 0.0241, 0.0191, 0.0325, 0.0428,\n",
       "        0.0347, 0.0546, 0.1113, 0.1351, 0.0647, 0.0428, 0.0529, 0.0407, 0.0240,\n",
       "        0.0316, 0.0529, 0.0420, 0.0221, 0.0162, 0.0236, 0.0310, 0.0222, 0.0337,\n",
       "        0.0643, 0.0492, 0.0251, 0.0172, 0.0236, 0.0184, 0.0124, 0.0176, 0.0325,\n",
       "        0.0397, 0.0234, 0.0185, 0.0307, 0.0407, 0.0325, 0.0515, 0.1030, 0.1188,\n",
       "        0.0598, 0.0399, 0.0529, 0.0397, 0.0254, 0.0350, 0.0623, 0.0466, 0.0266,\n",
       "        0.0204, 0.0325, 0.0420, 0.0326, 0.0511, 0.1010, 0.1144, 0.0621, 0.0436,\n",
       "        0.0643, 0.0492, 0.0357, 0.0526, 0.1010, 0.1188, 0.0739, 0.0598, 0.1030,\n",
       "        0.1351, 0.1113, 0.1776, 0.3597], device='cuda:0',\n",
       "       grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1827,  6.1037,  6.1033, -0.1785,  6.1047, -0.1762, -0.1782,  6.1049,\n",
       "         6.1048, -0.1760, -0.1747,  6.1071, -0.1756,  6.1085,  6.1066, -0.1782,\n",
       "         6.1048, -0.1746, -0.1744,  6.1089, -0.1736,  6.1124,  6.1089, -0.1762,\n",
       "        -0.1755,  6.1096,  6.1100, -0.1741,  6.1059, -0.1741, -0.1751,  6.1049,\n",
       "         6.1047, -0.1735, -0.1744,  6.1099, -0.1734,  6.1141,  6.1101, -0.1741,\n",
       "        -0.1736,  6.1138,  6.1133, -0.1697,  6.1107, -0.1694, -0.1726,  6.1071,\n",
       "        -0.1756,  6.1115,  6.1102, -0.1744,  6.1107, -0.1700, -0.1714,  6.1089,\n",
       "         6.1059, -0.1745, -0.1709,  6.1099, -0.1732,  6.1102,  6.1096, -0.1785,\n",
       "         6.1033, -0.1741, -0.1748,  6.1102, -0.1744,  6.1128,  6.1102, -0.1741,\n",
       "        -0.1744,  6.1131,  6.1147, -0.1694,  6.1102, -0.1707, -0.1711,  6.1085,\n",
       "        -0.1747,  6.1136,  6.1147, -0.1700,  6.1133, -0.1681, -0.1673,  6.1124,\n",
       "         6.1100, -0.1698, -0.1656,  6.1141, -0.1709,  6.1128,  6.1132, -0.1762,\n",
       "        -0.1782,  6.1108,  6.1102, -0.1745,  6.1101, -0.1698, -0.1713,  6.1096,\n",
       "         6.1089, -0.1701, -0.1673,  6.1138, -0.1714,  6.1131,  6.1130, -0.1760,\n",
       "         6.1066, -0.1722, -0.1711,  6.1115, -0.1726,  6.1136,  6.1130, -0.1746,\n",
       "        -0.1751,  6.1108,  6.1132, -0.1735,  6.1096, -0.1741, -0.1736,  6.1037,\n",
       "         6.1037, -0.1736, -0.1741,  6.1096, -0.1735,  6.1132,  6.1108, -0.1751,\n",
       "        -0.1746,  6.1130,  6.1136, -0.1726,  6.1115, -0.1711, -0.1722,  6.1066,\n",
       "        -0.1760,  6.1130,  6.1131, -0.1714,  6.1138, -0.1673, -0.1701,  6.1089,\n",
       "         6.1096, -0.1713, -0.1698,  6.1101, -0.1745,  6.1102,  6.1108, -0.1782,\n",
       "        -0.1762,  6.1132,  6.1128, -0.1709,  6.1141, -0.1656, -0.1698,  6.1100,\n",
       "         6.1124, -0.1673, -0.1681,  6.1133, -0.1700,  6.1147,  6.1136, -0.1747,\n",
       "         6.1085, -0.1711, -0.1707,  6.1102, -0.1694,  6.1147,  6.1131, -0.1744,\n",
       "        -0.1741,  6.1102,  6.1128, -0.1744,  6.1102, -0.1748, -0.1741,  6.1033,\n",
       "        -0.1785,  6.1096,  6.1102, -0.1732,  6.1099, -0.1709, -0.1745,  6.1059,\n",
       "         6.1089, -0.1714, -0.1700,  6.1107, -0.1744,  6.1102,  6.1115, -0.1756,\n",
       "         6.1071, -0.1726, -0.1694,  6.1107, -0.1697,  6.1133,  6.1138, -0.1736,\n",
       "        -0.1741,  6.1101,  6.1141, -0.1734,  6.1099, -0.1744, -0.1735,  6.1047,\n",
       "         6.1049, -0.1751, -0.1741,  6.1059, -0.1741,  6.1100,  6.1096, -0.1755,\n",
       "        -0.1762,  6.1089,  6.1124, -0.1736,  6.1089, -0.1744, -0.1746,  6.1048,\n",
       "        -0.1782,  6.1066,  6.1085, -0.1756,  6.1071, -0.1747, -0.1760,  6.1048,\n",
       "         6.1049, -0.1782, -0.1762,  6.1047, -0.1785,  6.1033,  6.1037, -0.1827],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = torch.exp(1j * log_phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9834-0.1817j, 0.9839-0.1785j, 0.9839-0.1789j, 0.9841-0.1775j,\n",
       "        0.9841-0.1775j, 0.9845-0.1753j, 0.9842-0.1772j, 0.9842-0.1773j,\n",
       "        0.9841-0.1774j, 0.9846-0.1751j, 0.9848-0.1738j, 0.9845-0.1752j,\n",
       "        0.9846-0.1747j, 0.9848-0.1738j, 0.9844-0.1757j, 0.9842-0.1772j,\n",
       "        0.9841-0.1774j, 0.9848-0.1737j, 0.9848-0.1735j, 0.9849-0.1734j,\n",
       "        0.9850-0.1727j, 0.9855-0.1699j, 0.9848-0.1735j, 0.9845-0.1753j,\n",
       "        0.9846-0.1746j, 0.9850-0.1727j, 0.9850-0.1724j, 0.9849-0.1732j,\n",
       "        0.9843-0.1764j, 0.9849-0.1733j, 0.9847-0.1742j, 0.9842-0.1773j,\n",
       "        0.9841-0.1775j, 0.9850-0.1727j, 0.9848-0.1736j, 0.9850-0.1724j,\n",
       "        0.9850-0.1725j, 0.9857-0.1682j, 0.9851-0.1722j, 0.9849-0.1732j,\n",
       "        0.9850-0.1727j, 0.9857-0.1686j, 0.9856-0.1691j, 0.9856-0.1689j,\n",
       "        0.9852-0.1716j, 0.9857-0.1686j, 0.9851-0.1717j, 0.9845-0.1752j,\n",
       "        0.9846-0.1747j, 0.9853-0.1709j, 0.9851-0.1722j, 0.9848-0.1735j,\n",
       "        0.9852-0.1716j, 0.9856-0.1691j, 0.9853-0.1706j, 0.9849-0.1734j,\n",
       "        0.9843-0.1764j, 0.9848-0.1736j, 0.9854-0.1700j, 0.9850-0.1724j,\n",
       "        0.9850-0.1723j, 0.9851-0.1721j, 0.9850-0.1727j, 0.9841-0.1775j,\n",
       "        0.9839-0.1789j, 0.9849-0.1733j, 0.9848-0.1739j, 0.9851-0.1721j,\n",
       "        0.9848-0.1736j, 0.9855-0.1696j, 0.9851-0.1722j, 0.9849-0.1733j,\n",
       "        0.9848-0.1735j, 0.9856-0.1692j, 0.9858-0.1677j, 0.9857-0.1686j,\n",
       "        0.9851-0.1722j, 0.9855-0.1699j, 0.9854-0.1702j, 0.9848-0.1738j,\n",
       "        0.9848-0.1738j, 0.9857-0.1688j, 0.9858-0.1677j, 0.9856-0.1691j,\n",
       "        0.9856-0.1691j, 0.9859-0.1674j, 0.9860-0.1665j, 0.9855-0.1699j,\n",
       "        0.9850-0.1724j, 0.9856-0.1690j, 0.9863-0.1649j, 0.9857-0.1682j,\n",
       "        0.9854-0.1700j, 0.9855-0.1696j, 0.9856-0.1692j, 0.9845-0.1753j,\n",
       "        0.9842-0.1772j, 0.9852-0.1715j, 0.9851-0.1722j, 0.9848-0.1736j,\n",
       "        0.9851-0.1722j, 0.9856-0.1690j, 0.9854-0.1704j, 0.9850-0.1727j,\n",
       "        0.9848-0.1735j, 0.9856-0.1693j, 0.9860-0.1665j, 0.9857-0.1686j,\n",
       "        0.9853-0.1706j, 0.9856-0.1692j, 0.9856-0.1694j, 0.9846-0.1751j,\n",
       "        0.9844-0.1757j, 0.9852-0.1714j, 0.9854-0.1702j, 0.9853-0.1709j,\n",
       "        0.9851-0.1717j, 0.9857-0.1688j, 0.9856-0.1694j, 0.9848-0.1737j,\n",
       "        0.9847-0.1742j, 0.9852-0.1715j, 0.9856-0.1692j, 0.9850-0.1727j,\n",
       "        0.9850-0.1727j, 0.9849-0.1733j, 0.9850-0.1727j, 0.9839-0.1785j,\n",
       "        0.9839-0.1785j, 0.9850-0.1727j, 0.9849-0.1733j, 0.9850-0.1727j,\n",
       "        0.9850-0.1727j, 0.9856-0.1692j, 0.9852-0.1715j, 0.9847-0.1742j,\n",
       "        0.9848-0.1737j, 0.9856-0.1694j, 0.9857-0.1688j, 0.9851-0.1717j,\n",
       "        0.9853-0.1709j, 0.9854-0.1702j, 0.9852-0.1714j, 0.9844-0.1757j,\n",
       "        0.9846-0.1751j, 0.9856-0.1694j, 0.9856-0.1692j, 0.9853-0.1706j,\n",
       "        0.9857-0.1686j, 0.9860-0.1665j, 0.9856-0.1693j, 0.9848-0.1735j,\n",
       "        0.9850-0.1727j, 0.9854-0.1704j, 0.9856-0.1690j, 0.9851-0.1722j,\n",
       "        0.9848-0.1736j, 0.9851-0.1722j, 0.9852-0.1715j, 0.9842-0.1772j,\n",
       "        0.9845-0.1753j, 0.9856-0.1692j, 0.9855-0.1696j, 0.9854-0.1700j,\n",
       "        0.9857-0.1682j, 0.9863-0.1649j, 0.9856-0.1690j, 0.9850-0.1724j,\n",
       "        0.9855-0.1699j, 0.9860-0.1665j, 0.9859-0.1674j, 0.9856-0.1691j,\n",
       "        0.9856-0.1691j, 0.9858-0.1677j, 0.9857-0.1688j, 0.9848-0.1738j,\n",
       "        0.9848-0.1738j, 0.9854-0.1702j, 0.9855-0.1699j, 0.9851-0.1722j,\n",
       "        0.9857-0.1686j, 0.9858-0.1677j, 0.9856-0.1692j, 0.9848-0.1735j,\n",
       "        0.9849-0.1733j, 0.9851-0.1722j, 0.9855-0.1696j, 0.9848-0.1736j,\n",
       "        0.9851-0.1721j, 0.9848-0.1739j, 0.9849-0.1733j, 0.9839-0.1789j,\n",
       "        0.9841-0.1775j, 0.9850-0.1727j, 0.9851-0.1721j, 0.9850-0.1723j,\n",
       "        0.9850-0.1724j, 0.9854-0.1700j, 0.9848-0.1736j, 0.9843-0.1764j,\n",
       "        0.9849-0.1734j, 0.9853-0.1706j, 0.9856-0.1691j, 0.9852-0.1716j,\n",
       "        0.9848-0.1735j, 0.9851-0.1722j, 0.9853-0.1709j, 0.9846-0.1747j,\n",
       "        0.9845-0.1752j, 0.9851-0.1717j, 0.9857-0.1686j, 0.9852-0.1716j,\n",
       "        0.9856-0.1689j, 0.9856-0.1691j, 0.9857-0.1686j, 0.9850-0.1727j,\n",
       "        0.9849-0.1732j, 0.9851-0.1722j, 0.9857-0.1682j, 0.9850-0.1725j,\n",
       "        0.9850-0.1724j, 0.9848-0.1736j, 0.9850-0.1727j, 0.9841-0.1775j,\n",
       "        0.9842-0.1773j, 0.9847-0.1742j, 0.9849-0.1733j, 0.9843-0.1764j,\n",
       "        0.9849-0.1732j, 0.9850-0.1724j, 0.9850-0.1727j, 0.9846-0.1746j,\n",
       "        0.9845-0.1753j, 0.9848-0.1735j, 0.9855-0.1699j, 0.9850-0.1727j,\n",
       "        0.9849-0.1734j, 0.9848-0.1735j, 0.9848-0.1737j, 0.9841-0.1774j,\n",
       "        0.9842-0.1772j, 0.9844-0.1757j, 0.9848-0.1738j, 0.9846-0.1747j,\n",
       "        0.9845-0.1752j, 0.9848-0.1738j, 0.9846-0.1751j, 0.9841-0.1774j,\n",
       "        0.9842-0.1773j, 0.9842-0.1772j, 0.9845-0.1753j, 0.9841-0.1775j,\n",
       "        0.9841-0.1775j, 0.9839-0.1789j, 0.9839-0.1785j, 0.9834-0.1817j],\n",
       "       device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_psi = amps * phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3537-0.0654j, 0.1748-0.0317j, 0.1095-0.0199j, 0.1329-0.0240j,\n",
       "        0.1013-0.0183j, 0.0589-0.0105j, 0.0728-0.0131j, 0.1170-0.0211j,\n",
       "        0.0994-0.0179j, 0.0518-0.0092j, 0.0352-0.0062j, 0.0484-0.0086j,\n",
       "        0.0633-0.0112j, 0.0429-0.0076j, 0.0611-0.0109j, 0.1126-0.0203j,\n",
       "        0.0994-0.0179j, 0.0503-0.0089j, 0.0321-0.0057j, 0.0414-0.0073j,\n",
       "        0.0320-0.0056j, 0.0201-0.0035j, 0.0262-0.0046j, 0.0459-0.0082j,\n",
       "        0.0614-0.0109j, 0.0345-0.0060j, 0.0251-0.0044j, 0.0391-0.0069j,\n",
       "        0.0521-0.0093j, 0.0393-0.0069j, 0.0589-0.0104j, 0.1170-0.0211j,\n",
       "        0.1013-0.0183j, 0.0507-0.0089j, 0.0320-0.0056j, 0.0401-0.0070j,\n",
       "        0.0302-0.0053j, 0.0183-0.0031j, 0.0231-0.0040j, 0.0391-0.0069j,\n",
       "        0.0320-0.0056j, 0.0174-0.0030j, 0.0122-0.0021j, 0.0181-0.0031j,\n",
       "        0.0233-0.0041j, 0.0170-0.0029j, 0.0248-0.0043j, 0.0484-0.0086j,\n",
       "        0.0633-0.0112j, 0.0332-0.0058j, 0.0219-0.0038j, 0.0305-0.0054j,\n",
       "        0.0233-0.0041j, 0.0160-0.0027j, 0.0218-0.0038j, 0.0414-0.0073j,\n",
       "        0.0521-0.0093j, 0.0311-0.0055j, 0.0237-0.0041j, 0.0401-0.0070j,\n",
       "        0.0521-0.0091j, 0.0421-0.0074j, 0.0637-0.0112j, 0.1329-0.0240j,\n",
       "        0.1095-0.0199j, 0.0537-0.0095j, 0.0341-0.0060j, 0.0421-0.0074j,\n",
       "        0.0320-0.0056j, 0.0189-0.0032j, 0.0237-0.0041j, 0.0393-0.0069j,\n",
       "        0.0321-0.0057j, 0.0170-0.0029j, 0.0118-0.0020j, 0.0170-0.0029j,\n",
       "        0.0219-0.0038j, 0.0155-0.0027j, 0.0223-0.0039j, 0.0429-0.0076j,\n",
       "        0.0352-0.0062j, 0.0180-0.0031j, 0.0118-0.0020j, 0.0160-0.0027j,\n",
       "        0.0122-0.0021j, 0.0081-0.0014j, 0.0108-0.0018j, 0.0201-0.0035j,\n",
       "        0.0251-0.0044j, 0.0146-0.0025j, 0.0110-0.0018j, 0.0183-0.0031j,\n",
       "        0.0237-0.0041j, 0.0189-0.0032j, 0.0284-0.0049j, 0.0589-0.0105j,\n",
       "        0.0728-0.0131j, 0.0364-0.0063j, 0.0237-0.0041j, 0.0311-0.0055j,\n",
       "        0.0231-0.0040j, 0.0146-0.0025j, 0.0191-0.0033j, 0.0345-0.0060j,\n",
       "        0.0262-0.0046j, 0.0147-0.0025j, 0.0108-0.0018j, 0.0174-0.0030j,\n",
       "        0.0218-0.0038j, 0.0170-0.0029j, 0.0252-0.0043j, 0.0518-0.0092j,\n",
       "        0.0611-0.0109j, 0.0327-0.0057j, 0.0223-0.0039j, 0.0332-0.0058j,\n",
       "        0.0248-0.0043j, 0.0180-0.0031j, 0.0252-0.0043j, 0.0503-0.0089j,\n",
       "        0.0589-0.0104j, 0.0364-0.0063j, 0.0284-0.0049j, 0.0507-0.0089j,\n",
       "        0.0637-0.0112j, 0.0537-0.0095j, 0.0814-0.0143j, 0.1748-0.0317j,\n",
       "        0.1748-0.0317j, 0.0814-0.0143j, 0.0537-0.0095j, 0.0637-0.0112j,\n",
       "        0.0507-0.0089j, 0.0284-0.0049j, 0.0364-0.0063j, 0.0589-0.0104j,\n",
       "        0.0503-0.0089j, 0.0252-0.0043j, 0.0180-0.0031j, 0.0248-0.0043j,\n",
       "        0.0332-0.0058j, 0.0223-0.0039j, 0.0327-0.0057j, 0.0611-0.0109j,\n",
       "        0.0518-0.0092j, 0.0252-0.0043j, 0.0170-0.0029j, 0.0218-0.0038j,\n",
       "        0.0174-0.0030j, 0.0108-0.0018j, 0.0147-0.0025j, 0.0262-0.0046j,\n",
       "        0.0345-0.0060j, 0.0191-0.0033j, 0.0146-0.0025j, 0.0231-0.0040j,\n",
       "        0.0311-0.0055j, 0.0237-0.0041j, 0.0364-0.0063j, 0.0728-0.0131j,\n",
       "        0.0589-0.0105j, 0.0284-0.0049j, 0.0189-0.0032j, 0.0237-0.0041j,\n",
       "        0.0183-0.0031j, 0.0110-0.0018j, 0.0146-0.0025j, 0.0251-0.0044j,\n",
       "        0.0201-0.0035j, 0.0108-0.0018j, 0.0081-0.0014j, 0.0122-0.0021j,\n",
       "        0.0160-0.0027j, 0.0118-0.0020j, 0.0180-0.0031j, 0.0352-0.0062j,\n",
       "        0.0429-0.0076j, 0.0223-0.0039j, 0.0155-0.0027j, 0.0219-0.0038j,\n",
       "        0.0170-0.0029j, 0.0118-0.0020j, 0.0170-0.0029j, 0.0321-0.0057j,\n",
       "        0.0393-0.0069j, 0.0237-0.0041j, 0.0189-0.0032j, 0.0320-0.0056j,\n",
       "        0.0421-0.0074j, 0.0341-0.0060j, 0.0537-0.0095j, 0.1095-0.0199j,\n",
       "        0.1329-0.0240j, 0.0637-0.0112j, 0.0421-0.0074j, 0.0521-0.0091j,\n",
       "        0.0401-0.0070j, 0.0237-0.0041j, 0.0311-0.0055j, 0.0521-0.0093j,\n",
       "        0.0414-0.0073j, 0.0218-0.0038j, 0.0160-0.0027j, 0.0233-0.0041j,\n",
       "        0.0305-0.0054j, 0.0219-0.0038j, 0.0332-0.0058j, 0.0633-0.0112j,\n",
       "        0.0484-0.0086j, 0.0248-0.0043j, 0.0170-0.0029j, 0.0233-0.0041j,\n",
       "        0.0181-0.0031j, 0.0122-0.0021j, 0.0174-0.0030j, 0.0320-0.0056j,\n",
       "        0.0391-0.0069j, 0.0231-0.0040j, 0.0183-0.0031j, 0.0302-0.0053j,\n",
       "        0.0401-0.0070j, 0.0320-0.0056j, 0.0507-0.0089j, 0.1013-0.0183j,\n",
       "        0.1170-0.0211j, 0.0589-0.0104j, 0.0393-0.0069j, 0.0521-0.0093j,\n",
       "        0.0391-0.0069j, 0.0251-0.0044j, 0.0345-0.0060j, 0.0614-0.0109j,\n",
       "        0.0459-0.0082j, 0.0262-0.0046j, 0.0201-0.0035j, 0.0320-0.0056j,\n",
       "        0.0414-0.0073j, 0.0321-0.0057j, 0.0503-0.0089j, 0.0994-0.0179j,\n",
       "        0.1126-0.0203j, 0.0611-0.0109j, 0.0429-0.0076j, 0.0633-0.0112j,\n",
       "        0.0484-0.0086j, 0.0352-0.0062j, 0.0518-0.0092j, 0.0994-0.0179j,\n",
       "        0.1170-0.0211j, 0.0728-0.0131j, 0.0589-0.0105j, 0.1013-0.0183j,\n",
       "        0.1329-0.0240j, 0.1095-0.0199j, 0.1748-0.0317j, 0.3537-0.0654j],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_recovered = torch.abs(predicted_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3597, 0.1776, 0.1113, 0.1351, 0.1030, 0.0598, 0.0739, 0.1188, 0.1010,\n",
       "        0.0526, 0.0357, 0.0492, 0.0643, 0.0436, 0.0621, 0.1144, 0.1010, 0.0511,\n",
       "        0.0326, 0.0420, 0.0325, 0.0204, 0.0266, 0.0466, 0.0623, 0.0350, 0.0254,\n",
       "        0.0397, 0.0529, 0.0399, 0.0598, 0.1188, 0.1030, 0.0515, 0.0325, 0.0407,\n",
       "        0.0307, 0.0185, 0.0234, 0.0397, 0.0325, 0.0176, 0.0124, 0.0184, 0.0236,\n",
       "        0.0172, 0.0251, 0.0492, 0.0643, 0.0337, 0.0222, 0.0310, 0.0236, 0.0162,\n",
       "        0.0221, 0.0420, 0.0529, 0.0316, 0.0240, 0.0407, 0.0529, 0.0428, 0.0647,\n",
       "        0.1351, 0.1113, 0.0546, 0.0347, 0.0428, 0.0325, 0.0191, 0.0241, 0.0399,\n",
       "        0.0326, 0.0172, 0.0120, 0.0172, 0.0222, 0.0157, 0.0226, 0.0436, 0.0357,\n",
       "        0.0183, 0.0120, 0.0162, 0.0124, 0.0082, 0.0110, 0.0204, 0.0254, 0.0148,\n",
       "        0.0112, 0.0185, 0.0240, 0.0191, 0.0288, 0.0598, 0.0739, 0.0370, 0.0241,\n",
       "        0.0316, 0.0234, 0.0148, 0.0194, 0.0350, 0.0266, 0.0149, 0.0110, 0.0176,\n",
       "        0.0221, 0.0172, 0.0256, 0.0526, 0.0621, 0.0332, 0.0226, 0.0337, 0.0251,\n",
       "        0.0183, 0.0256, 0.0511, 0.0598, 0.0370, 0.0288, 0.0515, 0.0647, 0.0546,\n",
       "        0.0827, 0.1776, 0.1776, 0.0827, 0.0546, 0.0647, 0.0515, 0.0288, 0.0370,\n",
       "        0.0598, 0.0511, 0.0256, 0.0183, 0.0251, 0.0337, 0.0226, 0.0332, 0.0621,\n",
       "        0.0526, 0.0256, 0.0172, 0.0221, 0.0176, 0.0110, 0.0149, 0.0266, 0.0350,\n",
       "        0.0194, 0.0148, 0.0234, 0.0316, 0.0241, 0.0370, 0.0739, 0.0598, 0.0288,\n",
       "        0.0191, 0.0240, 0.0185, 0.0112, 0.0148, 0.0254, 0.0204, 0.0110, 0.0082,\n",
       "        0.0124, 0.0162, 0.0120, 0.0183, 0.0357, 0.0436, 0.0226, 0.0157, 0.0222,\n",
       "        0.0172, 0.0120, 0.0172, 0.0326, 0.0399, 0.0241, 0.0191, 0.0325, 0.0428,\n",
       "        0.0347, 0.0546, 0.1113, 0.1351, 0.0647, 0.0428, 0.0529, 0.0407, 0.0240,\n",
       "        0.0316, 0.0529, 0.0420, 0.0221, 0.0162, 0.0236, 0.0310, 0.0222, 0.0337,\n",
       "        0.0643, 0.0492, 0.0251, 0.0172, 0.0236, 0.0184, 0.0124, 0.0176, 0.0325,\n",
       "        0.0397, 0.0234, 0.0185, 0.0307, 0.0407, 0.0325, 0.0515, 0.1030, 0.1188,\n",
       "        0.0598, 0.0399, 0.0529, 0.0397, 0.0254, 0.0350, 0.0623, 0.0466, 0.0266,\n",
       "        0.0204, 0.0325, 0.0420, 0.0326, 0.0511, 0.1010, 0.1144, 0.0621, 0.0436,\n",
       "        0.0643, 0.0492, 0.0357, 0.0526, 0.1010, 0.1188, 0.0739, 0.0598, 0.1030,\n",
       "        0.1351, 0.1113, 0.1776, 0.3597], device='cuda:0',\n",
       "       grad_fn=<AbsBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases_recovered = torch.angle(predicted_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1827, -0.1795, -0.1798, -0.1785, -0.1785, -0.1762, -0.1782, -0.1783,\n",
       "        -0.1784, -0.1760, -0.1747, -0.1761, -0.1756, -0.1746, -0.1766, -0.1782,\n",
       "        -0.1784, -0.1746, -0.1744, -0.1743, -0.1736, -0.1708, -0.1743, -0.1762,\n",
       "        -0.1755, -0.1736, -0.1732, -0.1741, -0.1773, -0.1741, -0.1751, -0.1783,\n",
       "        -0.1785, -0.1735, -0.1744, -0.1732, -0.1734, -0.1690, -0.1731, -0.1741,\n",
       "        -0.1736, -0.1694, -0.1699, -0.1697, -0.1725, -0.1694, -0.1726, -0.1761,\n",
       "        -0.1756, -0.1717, -0.1730, -0.1744, -0.1725, -0.1700, -0.1714, -0.1743,\n",
       "        -0.1773, -0.1745, -0.1709, -0.1732, -0.1732, -0.1730, -0.1736, -0.1785,\n",
       "        -0.1798, -0.1741, -0.1748, -0.1730, -0.1744, -0.1704, -0.1730, -0.1741,\n",
       "        -0.1744, -0.1700, -0.1685, -0.1694, -0.1730, -0.1707, -0.1711, -0.1746,\n",
       "        -0.1747, -0.1696, -0.1685, -0.1700, -0.1699, -0.1681, -0.1673, -0.1708,\n",
       "        -0.1732, -0.1698, -0.1656, -0.1690, -0.1709, -0.1704, -0.1700, -0.1762,\n",
       "        -0.1782, -0.1724, -0.1730, -0.1745, -0.1731, -0.1698, -0.1713, -0.1736,\n",
       "        -0.1743, -0.1701, -0.1673, -0.1694, -0.1714, -0.1700, -0.1702, -0.1760,\n",
       "        -0.1766, -0.1722, -0.1711, -0.1717, -0.1726, -0.1696, -0.1702, -0.1746,\n",
       "        -0.1751, -0.1724, -0.1700, -0.1735, -0.1736, -0.1741, -0.1736, -0.1795,\n",
       "        -0.1795, -0.1736, -0.1741, -0.1736, -0.1735, -0.1700, -0.1724, -0.1751,\n",
       "        -0.1746, -0.1702, -0.1696, -0.1726, -0.1717, -0.1711, -0.1722, -0.1766,\n",
       "        -0.1760, -0.1702, -0.1700, -0.1714, -0.1694, -0.1673, -0.1701, -0.1743,\n",
       "        -0.1736, -0.1713, -0.1698, -0.1731, -0.1745, -0.1730, -0.1724, -0.1782,\n",
       "        -0.1762, -0.1700, -0.1704, -0.1709, -0.1690, -0.1656, -0.1698, -0.1732,\n",
       "        -0.1708, -0.1673, -0.1681, -0.1699, -0.1700, -0.1685, -0.1696, -0.1747,\n",
       "        -0.1746, -0.1711, -0.1707, -0.1730, -0.1694, -0.1685, -0.1700, -0.1744,\n",
       "        -0.1741, -0.1730, -0.1704, -0.1744, -0.1730, -0.1748, -0.1741, -0.1798,\n",
       "        -0.1785, -0.1736, -0.1730, -0.1732, -0.1732, -0.1709, -0.1745, -0.1773,\n",
       "        -0.1743, -0.1714, -0.1700, -0.1725, -0.1744, -0.1730, -0.1717, -0.1756,\n",
       "        -0.1761, -0.1726, -0.1694, -0.1725, -0.1697, -0.1699, -0.1694, -0.1736,\n",
       "        -0.1741, -0.1731, -0.1690, -0.1734, -0.1732, -0.1744, -0.1735, -0.1785,\n",
       "        -0.1783, -0.1751, -0.1741, -0.1773, -0.1741, -0.1732, -0.1736, -0.1755,\n",
       "        -0.1762, -0.1743, -0.1708, -0.1736, -0.1743, -0.1744, -0.1746, -0.1784,\n",
       "        -0.1782, -0.1766, -0.1746, -0.1756, -0.1761, -0.1747, -0.1760, -0.1784,\n",
       "        -0.1783, -0.1782, -0.1762, -0.1785, -0.1785, -0.1798, -0.1795, -0.1827],\n",
       "       device='cuda:0', grad_fn=<AngleBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phases_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_amps = log_probs / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3582-0.0328j, -0.1769+0.0159j, -0.1108+0.0100j,  0.1346-0.0120j,\n",
       "        -0.1026+0.0092j,  0.0596-0.0053j,  0.0736-0.0066j, -0.1184+0.0106j,\n",
       "        -0.1006+0.0090j,  0.0524-0.0046j,  0.0356-0.0031j, -0.0490+0.0043j,\n",
       "         0.0640-0.0056j, -0.0434+0.0038j, -0.0619+0.0055j,  0.1140-0.0102j,\n",
       "        -0.1006+0.0090j,  0.0509-0.0045j,  0.0325-0.0028j, -0.0419+0.0037j,\n",
       "         0.0324-0.0028j, -0.0203+0.0017j, -0.0265+0.0023j,  0.0464-0.0041j,\n",
       "         0.0621-0.0055j, -0.0349+0.0030j, -0.0253+0.0022j,  0.0395-0.0034j,\n",
       "        -0.0527+0.0047j,  0.0398-0.0035j,  0.0596-0.0052j, -0.1184+0.0106j,\n",
       "        -0.1026+0.0092j,  0.0513-0.0045j,  0.0323-0.0028j, -0.0406+0.0035j,\n",
       "         0.0306-0.0027j, -0.0185+0.0016j, -0.0233+0.0020j,  0.0395-0.0034j,\n",
       "         0.0324-0.0028j, -0.0176+0.0015j, -0.0123+0.0011j,  0.0183-0.0016j,\n",
       "        -0.0235+0.0020j,  0.0172-0.0015j,  0.0250-0.0022j, -0.0490+0.0043j,\n",
       "         0.0640-0.0056j, -0.0336+0.0029j, -0.0221+0.0019j,  0.0308-0.0027j,\n",
       "        -0.0235+0.0020j,  0.0161-0.0014j,  0.0221-0.0019j, -0.0419+0.0037j,\n",
       "        -0.0527+0.0047j,  0.0314-0.0027j,  0.0239-0.0020j, -0.0406+0.0035j,\n",
       "         0.0527-0.0046j, -0.0426+0.0037j, -0.0644+0.0056j,  0.1346-0.0120j,\n",
       "        -0.1108+0.0100j,  0.0544-0.0047j,  0.0345-0.0030j, -0.0426+0.0037j,\n",
       "         0.0323-0.0028j, -0.0191+0.0016j, -0.0240+0.0021j,  0.0398-0.0035j,\n",
       "         0.0325-0.0028j, -0.0172+0.0015j, -0.0119+0.0010j,  0.0172-0.0015j,\n",
       "        -0.0221+0.0019j,  0.0156-0.0013j,  0.0225-0.0019j, -0.0434+0.0038j,\n",
       "         0.0356-0.0031j, -0.0182+0.0015j, -0.0119+0.0010j,  0.0161-0.0014j,\n",
       "        -0.0123+0.0011j,  0.0081-0.0007j,  0.0110-0.0009j, -0.0203+0.0017j,\n",
       "        -0.0253+0.0022j,  0.0147-0.0013j,  0.0111-0.0009j, -0.0185+0.0016j,\n",
       "         0.0239-0.0020j, -0.0191+0.0016j, -0.0287+0.0024j,  0.0596-0.0053j,\n",
       "         0.0736-0.0066j, -0.0369+0.0032j, -0.0240+0.0021j,  0.0314-0.0027j,\n",
       "        -0.0233+0.0020j,  0.0147-0.0013j,  0.0193-0.0017j, -0.0349+0.0030j,\n",
       "        -0.0265+0.0023j,  0.0149-0.0013j,  0.0110-0.0009j, -0.0176+0.0015j,\n",
       "         0.0221-0.0019j, -0.0172+0.0015j, -0.0255+0.0022j,  0.0524-0.0046j,\n",
       "        -0.0619+0.0055j,  0.0331-0.0029j,  0.0225-0.0019j, -0.0336+0.0029j,\n",
       "         0.0250-0.0022j, -0.0182+0.0015j, -0.0255+0.0022j,  0.0509-0.0045j,\n",
       "         0.0596-0.0052j, -0.0369+0.0032j, -0.0287+0.0024j,  0.0513-0.0045j,\n",
       "        -0.0644+0.0056j,  0.0544-0.0047j,  0.0824-0.0072j, -0.1769+0.0159j,\n",
       "        -0.1769+0.0159j,  0.0824-0.0072j,  0.0544-0.0047j, -0.0644+0.0056j,\n",
       "         0.0513-0.0045j, -0.0287+0.0024j, -0.0369+0.0032j,  0.0596-0.0052j,\n",
       "         0.0509-0.0045j, -0.0255+0.0022j, -0.0182+0.0015j,  0.0250-0.0022j,\n",
       "        -0.0336+0.0029j,  0.0225-0.0019j,  0.0331-0.0029j, -0.0619+0.0055j,\n",
       "         0.0524-0.0046j, -0.0255+0.0022j, -0.0172+0.0015j,  0.0221-0.0019j,\n",
       "        -0.0176+0.0015j,  0.0110-0.0009j,  0.0149-0.0013j, -0.0265+0.0023j,\n",
       "        -0.0349+0.0030j,  0.0193-0.0017j,  0.0147-0.0013j, -0.0233+0.0020j,\n",
       "         0.0314-0.0027j, -0.0240+0.0021j, -0.0369+0.0032j,  0.0736-0.0066j,\n",
       "         0.0596-0.0053j, -0.0287+0.0024j, -0.0191+0.0016j,  0.0239-0.0020j,\n",
       "        -0.0185+0.0016j,  0.0111-0.0009j,  0.0147-0.0013j, -0.0253+0.0022j,\n",
       "        -0.0203+0.0017j,  0.0110-0.0009j,  0.0081-0.0007j, -0.0123+0.0011j,\n",
       "         0.0161-0.0014j, -0.0119+0.0010j, -0.0182+0.0015j,  0.0356-0.0031j,\n",
       "        -0.0434+0.0038j,  0.0225-0.0019j,  0.0156-0.0013j, -0.0221+0.0019j,\n",
       "         0.0172-0.0015j, -0.0119+0.0010j, -0.0172+0.0015j,  0.0325-0.0028j,\n",
       "         0.0398-0.0035j, -0.0240+0.0021j, -0.0191+0.0016j,  0.0323-0.0028j,\n",
       "        -0.0426+0.0037j,  0.0345-0.0030j,  0.0544-0.0047j, -0.1108+0.0100j,\n",
       "         0.1346-0.0120j, -0.0644+0.0056j, -0.0426+0.0037j,  0.0527-0.0046j,\n",
       "        -0.0406+0.0035j,  0.0239-0.0020j,  0.0314-0.0027j, -0.0527+0.0047j,\n",
       "        -0.0419+0.0037j,  0.0221-0.0019j,  0.0161-0.0014j, -0.0235+0.0020j,\n",
       "         0.0308-0.0027j, -0.0221+0.0019j, -0.0336+0.0029j,  0.0640-0.0056j,\n",
       "        -0.0490+0.0043j,  0.0250-0.0022j,  0.0172-0.0015j, -0.0235+0.0020j,\n",
       "         0.0183-0.0016j, -0.0123+0.0011j, -0.0176+0.0015j,  0.0324-0.0028j,\n",
       "         0.0395-0.0034j, -0.0233+0.0020j, -0.0185+0.0016j,  0.0306-0.0027j,\n",
       "        -0.0406+0.0035j,  0.0323-0.0028j,  0.0513-0.0045j, -0.1026+0.0092j,\n",
       "        -0.1184+0.0106j,  0.0596-0.0052j,  0.0398-0.0035j, -0.0527+0.0047j,\n",
       "         0.0395-0.0034j, -0.0253+0.0022j, -0.0349+0.0030j,  0.0621-0.0055j,\n",
       "         0.0464-0.0041j, -0.0265+0.0023j, -0.0203+0.0017j,  0.0324-0.0028j,\n",
       "        -0.0419+0.0037j,  0.0325-0.0028j,  0.0509-0.0045j, -0.1006+0.0090j,\n",
       "         0.1140-0.0102j, -0.0619+0.0055j, -0.0434+0.0038j,  0.0640-0.0056j,\n",
       "        -0.0490+0.0043j,  0.0356-0.0031j,  0.0524-0.0046j, -0.1006+0.0090j,\n",
       "        -0.1184+0.0106j,  0.0736-0.0066j,  0.0596-0.0053j, -0.1026+0.0092j,\n",
       "         0.1346-0.0120j, -0.1108+0.0100j, -0.1769+0.0159j,  0.3582-0.0328j],\n",
       "       device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((log_probs + 1j * log_phases) / 2).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
