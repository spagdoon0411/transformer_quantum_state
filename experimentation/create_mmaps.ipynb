{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.multiprocessing.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "proj_path = \"/home/spandan/Projects/transformer_quantum_state\"\n",
    "os.chdir(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonians.Ising import Ising\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset for system size 10 from TFIM_ground_states/h_windows/10.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 12 from TFIM_ground_states/h_windows/12.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 14 from TFIM_ground_states/h_windows/14.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n"
     ]
    }
   ],
   "source": [
    "system_sizes = torch.arange(10, 15 + 1, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True, get_basis=True) for size in system_sizes]\n",
    "# data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-08-02T12-12-55.238\")\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"h_windows\")\n",
    "\n",
    "perc = (2**15 - 30000) / 2**15\n",
    "batch_size_dyn = lambda n: int(2**n * (1 - perc))\n",
    "\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(\n",
    "        data_dir_path,\n",
    "        batch_size=batch_size_dyn(ham.n),\n",
    "        # samples_in_epoch=100,\n",
    "        sampling_type=\"shuffled\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>h</th>\n",
       "      <th>energy</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-14.889630</td>\n",
       "      <td>[0.6283284965025702, -0.07985427455485967, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-15.776385</td>\n",
       "      <td>[0.5482456406333611, -0.09937707505092618, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-17.041148</td>\n",
       "      <td>[-0.42001585435609934, 0.1013754277719862, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-18.820983</td>\n",
       "      <td>[0.24132831196358626, -0.0755480292780341, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-21.014991</td>\n",
       "      <td>[-0.13584722067264499, 0.052360822750679555, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-23.407583</td>\n",
       "      <td>[0.089239800697954, -0.039977658610150256, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N    h     energy                                              state\n",
       "0  14  0.5 -14.889630  [0.6283284965025702, -0.07985427455485967, -0....\n",
       "1  14  0.7 -15.776385  [0.5482456406333611, -0.09937707505092618, -0....\n",
       "2  14  0.9 -17.041148  [-0.42001585435609934, 0.1013754277719862, 0.1...\n",
       "3  14  1.1 -18.820983  [0.24132831196358626, -0.0755480292780341, -0....\n",
       "4  14  1.3 -21.014991  [-0.13584722067264499, 0.052360822750679555, 0...\n",
       "5  14  1.5 -23.407583  [0.089239800697954, -0.039977658610150256, -0...."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6]) torch.Size([6, 1024]) torch.Size([10, 1024])\n",
      "torch.Size([1, 6]) torch.Size([6, 4096]) torch.Size([12, 4096])\n",
      "torch.Size([1, 6]) torch.Size([6, 16384]) torch.Size([14, 16384])\n"
     ]
    }
   ],
   "source": [
    "mmap_dir = \"mmap_data\"\n",
    "basis_memmap_dir = \"basis_sets\"\n",
    "parameter_memmap_dir = \"parameters\"\n",
    "ground_memmap_dir = \"ground_states\"\n",
    "for ham in Hamiltonians:\n",
    "\n",
    "    params = ham.training_dataset.param_tensor.unsqueeze(-1).T\n",
    "    ground = ham.training_dataset.ground_state_tensor\n",
    "    basis = ham.basis\n",
    "\n",
    "    print(params.shape, ground.shape, basis.shape)\n",
    "\n",
    "    # params should be of shape (1, n_samples) (and should match\n",
    "    # the number of ground state samples)\n",
    "    assert params.shape == (1, ground.shape[0])\n",
    "\n",
    "    # basis should be of shape (n, 2**n)\n",
    "    assert basis.shape == (ham.n, 2 ** ham.n)\n",
    "\n",
    "    # ground state components should match the basis size\n",
    "    assert ground.shape[1] == 2 ** basis.shape[0] == 2 ** ham.n\n",
    "\n",
    "    # basis_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "    #     dtype=np.int32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(ham.n, 2 ** ham.n),\n",
    "    # )\n",
    "\n",
    "    # parameter_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, parameter_memmap_dir, f\"param_{ham.n}.npy\"),\n",
    "    #     dtype=np.float32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(1, ground.shape[0]),\n",
    "    # )\n",
    "\n",
    "    # ground_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, ground_memmap_dir, f\"ground_{ham.n}.npy\"),\n",
    "    #     dtype=np.float32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(ground.shape[0], ground.shape[1]),\n",
    "    # )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "        basis.numpy(),\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, parameter_memmap_dir, f\"param_{ham.n}.npy\"),\n",
    "        params.numpy(),\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, ground_memmap_dir, f\"ground_{ham.n}.npy\"),\n",
    "        ground.numpy(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = ham.training_dataset.ground_state_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "metadata = {\n",
    "    \"num_samples\": num_samples,\n",
    "    \"basis_memmap_dir\": basis_memmap_dir,\n",
    "    \"parameter_memmap_dir\": parameter_memmap_dir,\n",
    "    \"ground_memmap_dir\": ground_memmap_dir,\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(mmap_dir, \"meta.json\")\n",
    "\n",
    "with open(metadata_file, \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.format import open_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_recovered = open_memmap(\n",
    "    os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "    mode=\"r\",\n",
    "    dtype=np.int32,\n",
    "    shape=(ham.n, 2 ** ham.n),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 1, ..., 0, 1, 1],\n",
       "        [0, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham.load_mmap(mmap_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/Projects/transformer_quantum_state/datasets/ising_memmap.py\", line 20, in prob_amp_collate\n    b0 = torch.stack([b[0] for b in batch]).to(device=\"cuda\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m ham\u001b[38;5;241m.\u001b[39mtraining_dataset:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sample)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/Projects/transformer_quantum_state/datasets/ising_memmap.py\", line 20, in prob_amp_collate\n    b0 = torch.stack([b[0] for b in batch]).to(device=\"cuda\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "for sample in ham.training_dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
