{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.multiprocessing.set_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "proj_path = \"C:\\\\Users\\\\csmuser\\\\Desktop\\\\Spandan_Suthar_Research\\\\transformer_quantum_state\"\n",
    "os.chdir(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonians.Ising import Ising\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csmuser\\Desktop\\Spandan_Suthar_Research\\transformer_quantum_state\\hamiltonians\\Ising.py:61: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  self.system_size.T, \"nearest_neighbor\", periodic\n",
      "C:\\Users\\csmuser\\Desktop\\Spandan_Suthar_Research\\transformer_quantum_state\\hamiltonians\\Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n",
      "C:\\Users\\csmuser\\Desktop\\Spandan_Suthar_Research\\transformer_quantum_state\\datasets\\batch_ising_dataset.py:62: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  self.ground_state_tensor = torch.tensor(dataframe[\"state\"].tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset for system size 10 from TFIM_ground_states\\h_windows_2\\10.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 12 from TFIM_ground_states\\h_windows_2\\12.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 14 from TFIM_ground_states\\h_windows_2\\14.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 16 from TFIM_ground_states\\h_windows_2\\16.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 18 from TFIM_ground_states\\h_windows_2\\18.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n",
      "Loaded dataset for system size 20 from TFIM_ground_states\\h_windows_2\\20.arrow.\n",
      "(h_min, h_step, h_max) = (0.5, -1, 1.5).\n"
     ]
    }
   ],
   "source": [
    "system_sizes = torch.arange(10, 20 + 1, 1).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True, get_basis=True) for size in system_sizes]\n",
    "# data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-08-02T12-12-55.238\")\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"h_windows_2\")\n",
    "\n",
    "perc = (2**15 - 30000) / 2**15\n",
    "batch_size_dyn = lambda n: int(2**n * (1 - perc))\n",
    "\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(\n",
    "        data_dir_path,\n",
    "        batch_size=batch_size_dyn(ham.n),\n",
    "        # samples_in_epoch=100,\n",
    "        sampling_type=\"shuffled\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>h</th>\n",
       "      <th>energy</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-21.270888</td>\n",
       "      <td>[-0.5973214806406636, 0.0759128884549983, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-22.536649</td>\n",
       "      <td>[0.49225871121089904, -0.08919197095933115, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-24.327480</td>\n",
       "      <td>[0.3419721558486439, -0.08221542029197858, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-26.866918</td>\n",
       "      <td>[0.14140532107910259, -0.04413721746693339, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-30.017054</td>\n",
       "      <td>[0.05832637996148782, -0.022471480361516655, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-33.438569</td>\n",
       "      <td>[-0.03172594408682963, 0.014211709451493259, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N    h     energy                                              state\n",
       "0  20  0.5 -21.270888  [-0.5973214806406636, 0.0759128884549983, 0.07...\n",
       "1  20  0.7 -22.536649  [0.49225871121089904, -0.08919197095933115, -0...\n",
       "2  20  0.9 -24.327480  [0.3419721558486439, -0.08221542029197858, -0....\n",
       "3  20  1.1 -26.866918  [0.14140532107910259, -0.04413721746693339, -0...\n",
       "4  20  1.3 -30.017054  [0.05832637996148782, -0.022471480361516655, -...\n",
       "5  20  1.5 -33.438569  [-0.03172594408682963, 0.014211709451493259, 0..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6]) torch.Size([6, 1024]) torch.Size([10, 1024])\n",
      "torch.Size([1, 6]) torch.Size([6, 4096]) torch.Size([12, 4096])\n",
      "torch.Size([1, 6]) torch.Size([6, 16384]) torch.Size([14, 16384])\n",
      "torch.Size([1, 6]) torch.Size([6, 65536]) torch.Size([16, 65536])\n",
      "torch.Size([1, 6]) torch.Size([6, 262144]) torch.Size([18, 262144])\n",
      "torch.Size([1, 6]) torch.Size([6, 1048576]) torch.Size([20, 1048576])\n"
     ]
    }
   ],
   "source": [
    "mmap_dir = \"mmap_data\"\n",
    "basis_memmap_dir = \"basis_sets\"\n",
    "parameter_memmap_dir = \"parameters\"\n",
    "ground_memmap_dir = \"ground_states\"\n",
    "for ham in Hamiltonians:\n",
    "\n",
    "    params = ham.training_dataset.param_tensor.unsqueeze(-1).T\n",
    "    ground = ham.training_dataset.ground_state_tensor\n",
    "    basis = ham.basis\n",
    "\n",
    "    print(params.shape, ground.shape, basis.shape)\n",
    "\n",
    "    # params should be of shape (1, n_samples) (and should match\n",
    "    # the number of ground state samples)\n",
    "    assert params.shape == (1, ground.shape[0])\n",
    "\n",
    "    # basis should be of shape (n, 2**n)\n",
    "    assert basis.shape == (ham.n, 2 ** ham.n)\n",
    "\n",
    "    # ground state components should match the basis size\n",
    "    assert ground.shape[1] == 2 ** basis.shape[0] == 2 ** ham.n\n",
    "\n",
    "    # basis_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "    #     dtype=np.int32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(ham.n, 2 ** ham.n),\n",
    "    # )\n",
    "\n",
    "    # parameter_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, parameter_memmap_dir, f\"param_{ham.n}.npy\"),\n",
    "    #     dtype=np.float32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(1, ground.shape[0]),\n",
    "    # )\n",
    "\n",
    "    # ground_memmap = np.memmap(\n",
    "    #     os.path.join(mmap_dir, ground_memmap_dir, f\"ground_{ham.n}.npy\"),\n",
    "    #     dtype=np.float32,\n",
    "    #     mode=\"w+\",\n",
    "    #     shape=(ground.shape[0], ground.shape[1]),\n",
    "    # )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "        basis.numpy(),\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, parameter_memmap_dir, f\"param_{ham.n}.npy\"),\n",
    "        params.numpy(),\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(mmap_dir, ground_memmap_dir, f\"ground_{ham.n}.npy\"),\n",
    "        ground.numpy(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = ham.training_dataset.ground_state_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "metadata = {\n",
    "    \"num_samples\": num_samples,\n",
    "    \"basis_memmap_dir\": basis_memmap_dir,\n",
    "    \"parameter_memmap_dir\": parameter_memmap_dir,\n",
    "    \"ground_memmap_dir\": ground_memmap_dir,\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(mmap_dir, \"meta.json\")\n",
    "\n",
    "with open(metadata_file, \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.format import open_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_recovered = open_memmap(\n",
    "    os.path.join(mmap_dir, basis_memmap_dir, f\"basis_{ham.n}.npy\"),\n",
    "    mode=\"r\",\n",
    "    dtype=np.int32,\n",
    "    shape=(ham.n, 2 ** ham.n),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 1, ..., 0, 1, 1],\n",
       "        [0, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham.load_mmap(mmap_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in ham.training_dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
