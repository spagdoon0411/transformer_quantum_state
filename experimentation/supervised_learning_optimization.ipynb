{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from optimizer_supervised import Optimizer\n",
    "from Ising import Ising\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup():\n",
    "    # Setup for PyTorch:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        print(\"PyTorch is using GPU {}\".format(torch.cuda.current_device()))\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "        print(\"GPU unavailable; using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 8],\n",
       "        [10],\n",
       "        [12],\n",
       "        [14],\n",
       "        [16],\n",
       "        [18],\n",
       "        [20]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify \"cpu\" or \"cuda\" as the device\n",
    "system_sizes = torch.arange(2, 21, 2, device=\"cpu\").reshape(-1, 1)\n",
    "system_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 8],\n",
       "        [10],\n",
       "        [12],\n",
       "        [14],\n",
       "        [16],\n",
       "        [18],\n",
       "        [20]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/aten/src/ATen/native/TensorShape.cpp:3675.)\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Causes small allocation for Hamiltonian basis tensors\n",
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = Hamiltonians[0]\n",
    "ham.system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 1,  ..., 0, 1, 1],\n",
       "        [0, 1, 0,  ..., 1, 0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonians[4].basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(Hamiltonians[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37748736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbasis = Hamiltonians[8].basis\n",
    "testbasis.element_size() * testbasis.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "bytes_in_gb = 1024**3\n",
    "\n",
    "# Get the sizes of Hamiltonians\n",
    "sizes = [\n",
    "    hamiltonian.basis.element_size() * hamiltonian.basis.numel() / bytes_in_gb\n",
    "    for hamiltonian in Hamiltonians\n",
    "]\n",
    "\n",
    "# Plot the sizes\n",
    "plt.plot(sizes)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Size (Gb)\")\n",
    "plt.title(\"Sizes of Hamiltonian Basis Tensors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorsize(tensor):\n",
    "    return tensor.element_size() * tensor.numel() / bytes_in_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.980232238769531e-07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = Hamiltonians[9]\n",
    "tensorsize(ham.connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 1,  2],\n",
       "        [ 2,  3],\n",
       "        [ 3,  4],\n",
       "        [ 4,  5],\n",
       "        [ 5,  6],\n",
       "        [ 6,  7],\n",
       "        [ 7,  8],\n",
       "        [ 8,  9],\n",
       "        [ 9, 10],\n",
       "        [10, 11],\n",
       "        [11, 12],\n",
       "        [12, 13],\n",
       "        [13, 14],\n",
       "        [14, 15],\n",
       "        [15, 16],\n",
       "        [16, 17],\n",
       "        [17, 18],\n",
       "        [18, 19],\n",
       "        [19,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham.connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 1000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Small allocation for model parameters, layers, etc.\n",
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): TQSPositionalEncoding1D(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_Q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_K): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_V): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (amp_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (phase_head): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = torch.tensor([[0.5, 1.5]])\n",
    "param_step = torch.tensor([0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgen = opt.generate_parameter_points(param_range, param_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5100], device='cuda:0')\n",
      "tensor([0.5200], device='cuda:0')\n",
      "tensor([0.5300], device='cuda:0')\n",
      "tensor([0.5400], device='cuda:0')\n",
      "tensor([0.5500], device='cuda:0')\n",
      "tensor([0.5600], device='cuda:0')\n",
      "tensor([0.5700], device='cuda:0')\n",
      "tensor([0.5800], device='cuda:0')\n",
      "tensor([0.5900], device='cuda:0')\n",
      "tensor([0.6000], device='cuda:0')\n",
      "tensor([0.6100], device='cuda:0')\n",
      "tensor([0.6200], device='cuda:0')\n",
      "tensor([0.6300], device='cuda:0')\n",
      "tensor([0.6400], device='cuda:0')\n",
      "tensor([0.6500], device='cuda:0')\n",
      "tensor([0.6600], device='cuda:0')\n",
      "tensor([0.6700], device='cuda:0')\n",
      "tensor([0.6800], device='cuda:0')\n",
      "tensor([0.6900], device='cuda:0')\n",
      "tensor([0.7000], device='cuda:0')\n",
      "tensor([0.7100], device='cuda:0')\n",
      "tensor([0.7200], device='cuda:0')\n",
      "tensor([0.7300], device='cuda:0')\n",
      "tensor([0.7400], device='cuda:0')\n",
      "tensor([0.7500], device='cuda:0')\n",
      "tensor([0.7600], device='cuda:0')\n",
      "tensor([0.7700], device='cuda:0')\n",
      "tensor([0.7800], device='cuda:0')\n",
      "tensor([0.7900], device='cuda:0')\n",
      "tensor([0.8000], device='cuda:0')\n",
      "tensor([0.8100], device='cuda:0')\n",
      "tensor([0.8200], device='cuda:0')\n",
      "tensor([0.8300], device='cuda:0')\n",
      "tensor([0.8400], device='cuda:0')\n",
      "tensor([0.8500], device='cuda:0')\n",
      "tensor([0.8600], device='cuda:0')\n",
      "tensor([0.8700], device='cuda:0')\n",
      "tensor([0.8800], device='cuda:0')\n",
      "tensor([0.8900], device='cuda:0')\n",
      "tensor([0.9000], device='cuda:0')\n",
      "tensor([0.9100], device='cuda:0')\n",
      "tensor([0.9200], device='cuda:0')\n",
      "tensor([0.9300], device='cuda:0')\n",
      "tensor([0.9400], device='cuda:0')\n",
      "tensor([0.9500], device='cuda:0')\n",
      "tensor([0.9600], device='cuda:0')\n",
      "tensor([0.9700], device='cuda:0')\n",
      "tensor([0.9800], device='cuda:0')\n",
      "tensor([0.9900], device='cuda:0')\n",
      "tensor([1.], device='cuda:0')\n",
      "tensor([1.0100], device='cuda:0')\n",
      "tensor([1.0200], device='cuda:0')\n",
      "tensor([1.0300], device='cuda:0')\n",
      "tensor([1.0400], device='cuda:0')\n",
      "tensor([1.0500], device='cuda:0')\n",
      "tensor([1.0600], device='cuda:0')\n",
      "tensor([1.0700], device='cuda:0')\n",
      "tensor([1.0800], device='cuda:0')\n",
      "tensor([1.0900], device='cuda:0')\n",
      "tensor([1.1000], device='cuda:0')\n",
      "tensor([1.1100], device='cuda:0')\n",
      "tensor([1.1200], device='cuda:0')\n",
      "tensor([1.1300], device='cuda:0')\n",
      "tensor([1.1400], device='cuda:0')\n",
      "tensor([1.1500], device='cuda:0')\n",
      "tensor([1.1600], device='cuda:0')\n",
      "tensor([1.1700], device='cuda:0')\n",
      "tensor([1.1800], device='cuda:0')\n",
      "tensor([1.1900], device='cuda:0')\n",
      "tensor([1.2000], device='cuda:0')\n",
      "tensor([1.2100], device='cuda:0')\n",
      "tensor([1.2200], device='cuda:0')\n",
      "tensor([1.2300], device='cuda:0')\n",
      "tensor([1.2400], device='cuda:0')\n",
      "tensor([1.2500], device='cuda:0')\n",
      "tensor([1.2600], device='cuda:0')\n",
      "tensor([1.2700], device='cuda:0')\n",
      "tensor([1.2800], device='cuda:0')\n",
      "tensor([1.2900], device='cuda:0')\n",
      "tensor([1.3000], device='cuda:0')\n",
      "tensor([1.3100], device='cuda:0')\n",
      "tensor([1.3200], device='cuda:0')\n",
      "tensor([1.3300], device='cuda:0')\n",
      "tensor([1.3400], device='cuda:0')\n",
      "tensor([1.3500], device='cuda:0')\n",
      "tensor([1.3600], device='cuda:0')\n",
      "tensor([1.3700], device='cuda:0')\n",
      "tensor([1.3800], device='cuda:0')\n",
      "tensor([1.3900], device='cuda:0')\n",
      "tensor([1.4000], device='cuda:0')\n",
      "tensor([1.4100], device='cuda:0')\n",
      "tensor([1.4200], device='cuda:0')\n",
      "tensor([1.4300], device='cuda:0')\n",
      "tensor([1.4400], device='cuda:0')\n",
      "tensor([1.4500], device='cuda:0')\n",
      "tensor([1.4600], device='cuda:0')\n",
      "tensor([1.4700], device='cuda:0')\n",
      "tensor([1.4800], device='cuda:0')\n",
      "tensor([1.4900], device='cuda:0')\n",
      "tensor([1.5000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for point in pgen:\n",
    "    pointtens = torch.tensor(point, device=\"cuda\")\n",
    "    print(pointtens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20179128646850586"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated() / bytes_in_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran forward for tensor([2]) spins at point (0.5,)\n",
      "Ran forward for tensor([2]) spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([2]) spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([2]) spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([2]) spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([2]) spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([2]) spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([2]) spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([2]) spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([2]) spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([2]) spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([2]) spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([2]) spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([2]) spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([2]) spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([2]) spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([2]) spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([2]) spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([2]) spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([2]) spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([2]) spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([2]) spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([2]) spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([2]) spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([2]) spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([2]) spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([2]) spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([2]) spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([2]) spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([2]) spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([2]) spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([2]) spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([2]) spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([2]) spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([2]) spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([2]) spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([2]) spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([2]) spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([2]) spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([2]) spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([2]) spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([2]) spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([2]) spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([2]) spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([2]) spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([2]) spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([2]) spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([2]) spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([2]) spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([2]) spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([2]) spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([2]) spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([2]) spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([2]) spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([2]) spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([2]) spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([2]) spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([2]) spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([2]) spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([2]) spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([2]) spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([2]) spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([2]) spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([2]) spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([2]) spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([2]) spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([2]) spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([2]) spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([2]) spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([2]) spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([2]) spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([2]) spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([2]) spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([2]) spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([2]) spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([2]) spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([2]) spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([2]) spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([2]) spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([2]) spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([2]) spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([2]) spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([2]) spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([2]) spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([2]) spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([2]) spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([2]) spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([2]) spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([2]) spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([2]) spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([2]) spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([2]) spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([2]) spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([2]) spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([2]) spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([2]) spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([2]) spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([2]) spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([2]) spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([2]) spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([2]) spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([4]) spins at point (0.5,)\n",
      "Ran forward for tensor([4]) spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([4]) spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([4]) spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([4]) spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([4]) spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([4]) spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([4]) spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([4]) spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([4]) spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([4]) spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([4]) spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([4]) spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([4]) spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([4]) spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([4]) spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([4]) spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([4]) spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([4]) spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([4]) spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([4]) spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([4]) spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([4]) spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([4]) spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([4]) spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([4]) spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([4]) spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([4]) spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([4]) spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([4]) spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([4]) spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([4]) spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([4]) spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([4]) spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([4]) spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([4]) spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([4]) spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([4]) spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([4]) spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([4]) spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([4]) spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([4]) spins at point (0.9099999908357859,)\n",
      "Ran forward for tensor([4]) spins at point (0.9199999906122684,)\n",
      "Ran forward for tensor([4]) spins at point (0.929999990388751,)\n",
      "Ran forward for tensor([4]) spins at point (0.9399999901652336,)\n",
      "Ran forward for tensor([4]) spins at point (0.9499999899417162,)\n",
      "Ran forward for tensor([4]) spins at point (0.9599999897181988,)\n",
      "Ran forward for tensor([4]) spins at point (0.9699999894946814,)\n",
      "Ran forward for tensor([4]) spins at point (0.9799999892711639,)\n",
      "Ran forward for tensor([4]) spins at point (0.9899999890476465,)\n",
      "Ran forward for tensor([4]) spins at point (0.9999999888241291,)\n",
      "Ran forward for tensor([4]) spins at point (1.0099999886006117,)\n",
      "Ran forward for tensor([4]) spins at point (1.0199999883770943,)\n",
      "Ran forward for tensor([4]) spins at point (1.0299999881535769,)\n",
      "Ran forward for tensor([4]) spins at point (1.0399999879300594,)\n",
      "Ran forward for tensor([4]) spins at point (1.049999987706542,)\n",
      "Ran forward for tensor([4]) spins at point (1.0599999874830246,)\n",
      "Ran forward for tensor([4]) spins at point (1.0699999872595072,)\n",
      "Ran forward for tensor([4]) spins at point (1.0799999870359898,)\n",
      "Ran forward for tensor([4]) spins at point (1.0899999868124723,)\n",
      "Ran forward for tensor([4]) spins at point (1.099999986588955,)\n",
      "Ran forward for tensor([4]) spins at point (1.1099999863654375,)\n",
      "Ran forward for tensor([4]) spins at point (1.11999998614192,)\n",
      "Ran forward for tensor([4]) spins at point (1.1299999859184027,)\n",
      "Ran forward for tensor([4]) spins at point (1.1399999856948853,)\n",
      "Ran forward for tensor([4]) spins at point (1.1499999854713678,)\n",
      "Ran forward for tensor([4]) spins at point (1.1599999852478504,)\n",
      "Ran forward for tensor([4]) spins at point (1.169999985024333,)\n",
      "Ran forward for tensor([4]) spins at point (1.1799999848008156,)\n",
      "Ran forward for tensor([4]) spins at point (1.1899999845772982,)\n",
      "Ran forward for tensor([4]) spins at point (1.1999999843537807,)\n",
      "Ran forward for tensor([4]) spins at point (1.2099999841302633,)\n",
      "Ran forward for tensor([4]) spins at point (1.219999983906746,)\n",
      "Ran forward for tensor([4]) spins at point (1.2299999836832285,)\n",
      "Ran forward for tensor([4]) spins at point (1.239999983459711,)\n",
      "Ran forward for tensor([4]) spins at point (1.2499999832361937,)\n",
      "Ran forward for tensor([4]) spins at point (1.2599999830126762,)\n",
      "Ran forward for tensor([4]) spins at point (1.2699999827891588,)\n",
      "Ran forward for tensor([4]) spins at point (1.2799999825656414,)\n",
      "Ran forward for tensor([4]) spins at point (1.289999982342124,)\n",
      "Ran forward for tensor([4]) spins at point (1.2999999821186066,)\n",
      "Ran forward for tensor([4]) spins at point (1.3099999818950891,)\n",
      "Ran forward for tensor([4]) spins at point (1.3199999816715717,)\n",
      "Ran forward for tensor([4]) spins at point (1.3299999814480543,)\n",
      "Ran forward for tensor([4]) spins at point (1.339999981224537,)\n",
      "Ran forward for tensor([4]) spins at point (1.3499999810010195,)\n",
      "Ran forward for tensor([4]) spins at point (1.359999980777502,)\n",
      "Ran forward for tensor([4]) spins at point (1.3699999805539846,)\n",
      "Ran forward for tensor([4]) spins at point (1.3799999803304672,)\n",
      "Ran forward for tensor([4]) spins at point (1.3899999801069498,)\n",
      "Ran forward for tensor([4]) spins at point (1.3999999798834324,)\n",
      "Ran forward for tensor([4]) spins at point (1.409999979659915,)\n",
      "Ran forward for tensor([4]) spins at point (1.4199999794363976,)\n",
      "Ran forward for tensor([4]) spins at point (1.4299999792128801,)\n",
      "Ran forward for tensor([4]) spins at point (1.4399999789893627,)\n",
      "Ran forward for tensor([4]) spins at point (1.4499999787658453,)\n",
      "Ran forward for tensor([4]) spins at point (1.4599999785423279,)\n",
      "Ran forward for tensor([4]) spins at point (1.4699999783188105,)\n",
      "Ran forward for tensor([4]) spins at point (1.479999978095293,)\n",
      "Ran forward for tensor([4]) spins at point (1.4899999778717756,)\n",
      "Ran forward for tensor([4]) spins at point (1.4999999776482582,)\n",
      "Ran forward for tensor([6]) spins at point (0.5,)\n",
      "Ran forward for tensor([6]) spins at point (0.5099999997764826,)\n",
      "Ran forward for tensor([6]) spins at point (0.5199999995529652,)\n",
      "Ran forward for tensor([6]) spins at point (0.5299999993294477,)\n",
      "Ran forward for tensor([6]) spins at point (0.5399999991059303,)\n",
      "Ran forward for tensor([6]) spins at point (0.5499999988824129,)\n",
      "Ran forward for tensor([6]) spins at point (0.5599999986588955,)\n",
      "Ran forward for tensor([6]) spins at point (0.5699999984353781,)\n",
      "Ran forward for tensor([6]) spins at point (0.5799999982118607,)\n",
      "Ran forward for tensor([6]) spins at point (0.5899999979883432,)\n",
      "Ran forward for tensor([6]) spins at point (0.5999999977648258,)\n",
      "Ran forward for tensor([6]) spins at point (0.6099999975413084,)\n",
      "Ran forward for tensor([6]) spins at point (0.619999997317791,)\n",
      "Ran forward for tensor([6]) spins at point (0.6299999970942736,)\n",
      "Ran forward for tensor([6]) spins at point (0.6399999968707561,)\n",
      "Ran forward for tensor([6]) spins at point (0.6499999966472387,)\n",
      "Ran forward for tensor([6]) spins at point (0.6599999964237213,)\n",
      "Ran forward for tensor([6]) spins at point (0.6699999962002039,)\n",
      "Ran forward for tensor([6]) spins at point (0.6799999959766865,)\n",
      "Ran forward for tensor([6]) spins at point (0.6899999957531691,)\n",
      "Ran forward for tensor([6]) spins at point (0.6999999955296516,)\n",
      "Ran forward for tensor([6]) spins at point (0.7099999953061342,)\n",
      "Ran forward for tensor([6]) spins at point (0.7199999950826168,)\n",
      "Ran forward for tensor([6]) spins at point (0.7299999948590994,)\n",
      "Ran forward for tensor([6]) spins at point (0.739999994635582,)\n",
      "Ran forward for tensor([6]) spins at point (0.7499999944120646,)\n",
      "Ran forward for tensor([6]) spins at point (0.7599999941885471,)\n",
      "Ran forward for tensor([6]) spins at point (0.7699999939650297,)\n",
      "Ran forward for tensor([6]) spins at point (0.7799999937415123,)\n",
      "Ran forward for tensor([6]) spins at point (0.7899999935179949,)\n",
      "Ran forward for tensor([6]) spins at point (0.7999999932944775,)\n",
      "Ran forward for tensor([6]) spins at point (0.80999999307096,)\n",
      "Ran forward for tensor([6]) spins at point (0.8199999928474426,)\n",
      "Ran forward for tensor([6]) spins at point (0.8299999926239252,)\n",
      "Ran forward for tensor([6]) spins at point (0.8399999924004078,)\n",
      "Ran forward for tensor([6]) spins at point (0.8499999921768904,)\n",
      "Ran forward for tensor([6]) spins at point (0.859999991953373,)\n",
      "Ran forward for tensor([6]) spins at point (0.8699999917298555,)\n",
      "Ran forward for tensor([6]) spins at point (0.8799999915063381,)\n",
      "Ran forward for tensor([6]) spins at point (0.8899999912828207,)\n",
      "Ran forward for tensor([6]) spins at point (0.8999999910593033,)\n",
      "Ran forward for tensor([6]) spins at point (0.9099999908357859,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/Projects/tqs/model.py:228: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cProfile\u001b[38;5;241m.\u001b[39mProfile() \u001b[38;5;28;01mas\u001b[39;00m pr:\n\u001b[0;32m----> 2\u001b[0m     opt\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m      3\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs, param_range\u001b[38;5;241m=\u001b[39mparam_range, param_step\u001b[38;5;241m=\u001b[39mparam_step, start_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised.py:315\u001b[0m, in \u001b[0;36mOptimizer.train\u001b[0;34m(self, epochs, param_range, param_step, ensemble_id, start_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# NOTE: the system size is constant for this inner loop but must be reset\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# here because leaving it out (or, equivalently, setting it to None) would\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# cause the model to sample a random system size. See set_param in model.py.\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m dummy_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(H\u001b[38;5;241m.\u001b[39mbasis, compute_phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRan forward for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m spins at point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# loss = self.calculate_mse_step(\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#     H, param, basis_batch=None, use_symmetry=True\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/model.py:309\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, spins, compute_phase)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# src_i = src_i + self.pos_embedding[:len(src_i)]  # (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    308\u001b[0m src_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src_i, system_size)  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m output_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(\n\u001b[1;32m    310\u001b[0m     src_i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_mask\n\u001b[1;32m    311\u001b[0m )  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    312\u001b[0m psi_output \u001b[38;5;241m=\u001b[39m output_i[\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_prefix_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[1;32m    314\u001b[0m ]  \u001b[38;5;66;03m# only use the physical degrees of freedom\u001b[39;00m\n\u001b[1;32m    315\u001b[0m amp_i \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp_head(psi_output), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    317\u001b[0m )  \u001b[38;5;66;03m# (seq, batch, phys_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask, is_causal\u001b[38;5;241m=\u001b[39mis_causal, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:119\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:128\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: Tensor, attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    129\u001b[0m         x,\n\u001b[1;32m    130\u001b[0m         x,\n\u001b[1;32m    131\u001b[0m         x,\n\u001b[1;32m    132\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    133\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    134\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:142\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     87\u001b[0m             query: Tensor,\n\u001b[1;32m     88\u001b[0m             key: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m             attn_mask: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m             average_attn_weights: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Optional[Tensor]]:\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mNote::\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m      head of shape :math:`(N, num_heads, L, S)`.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(query, key, value, key_padding_mask,\n\u001b[1;32m    143\u001b[0m                               need_weights, attn_mask, average_attn_weights)\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:174\u001b[0m, in \u001b[0;36mMultiheadAttention._forward_impl\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m    171\u001b[0m scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(head_dim) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    173\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_Q(query)\n\u001b[0;32m--> 174\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_K(key)\n\u001b[1;32m    175\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_V(value)\n\u001b[1;32m    177\u001b[0m q \u001b[38;5;241m=\u001b[39m scaling \u001b[38;5;241m*\u001b[39m q\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with cProfile.Profile() as pr:\n",
    "    opt.train(\n",
    "        epochs=epochs, param_range=param_range, param_step=param_step, start_iter=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4666348 function calls (3954845 primitive calls) in 5.515 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   762000    2.049    0.000    3.767    0.000 _device.py:74(__torch_function__)\n",
      "     1500    0.002    0.000    0.011    0.000 _tensor.py:1037(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:1908(_run_once)\n",
      "        4    0.000    0.000    0.000    0.000 base_events.py:732(time)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:119(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
      "        1    0.000    0.000    0.010    0.010 decorator.py:229(fun)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:127(__lt__)\n",
      "        2    0.000    0.000    0.000    0.000 events.py:86(_run)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        1    0.000    0.000    0.010    0.010 history.py:55(only_when_enabled)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:833(_writeout_input_cache)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:839(_writeout_output_cache)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:845(writeout_cache)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2782(name)\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2794(kind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2874(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2882(args)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2905(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2935(apply_defaults)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3075(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3119(_bind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3254(bind)\n",
      "        2    0.000    0.000    0.000    0.000 ioloop.py:742(_run_callback)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:585(_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:678(_flush_buffer)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:685(_rotate_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:131(step)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:178(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:181(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:185(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:218(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:25(_check_verbose_deprecated_warning)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:269(get_lr)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:35(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:57(with_counter)\n",
      "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:87(_initial_step)\n",
      "    50500    0.111    0.000    4.483    0.000 model.py:143(set_param)\n",
      "    50500    0.517    0.000    3.490    0.000 model.py:158(init_seq)\n",
      "   252501    0.284    0.000    0.591    0.000 module.py:1711(__setattr__)\n",
      "    51000    0.003    0.000    0.003    0.000 optimizer_supervised.py:200(generate_parameter_range)\n",
      "  501/500    0.007    0.000    0.033    0.000 optimizer_supervised.py:210(generate_parameter_points)\n",
      "      2/1    0.064    0.032    5.490    5.490 optimizer_supervised.py:240(train)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer_supervised.py:285(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer_supervised.py:61(lr_schedule)\n",
      "   252501    0.117    0.000    0.168    0.000 parameter.py:8(__instancecheck__)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:750(_process_events)\n",
      "        1    0.000    0.000    0.000    0.000 selectors.py:451(select)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:299(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:302(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:308(_release_save)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:311(_acquire_restore)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:314(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:627(clear)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1512(_notify_trait)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1523(notify_change)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1527(_notify_observers)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:2304(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3474(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3486(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3624(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3631(set)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:689(set)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:708(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:718(_validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:727(_cross_validate)\n",
      "       22    0.000    0.000    0.000    0.000 typing.py:2132(cast)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _heapq.heappop}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "   202010    0.014    0.000    0.014    0.000 {built-in method builtins.getattr}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "757514/505013    0.090    0.000    0.241    0.000 {built-in method builtins.isinstance}\n",
      "     1502    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "     1100    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "     1500    0.001    0.000    0.001    0.000 {built-in method torch._C._get_tracing_state}\n",
      "101000/50500    0.128    0.000    0.146    0.000 {built-in method torch.diag}\n",
      "    50500    0.007    0.000    0.007    0.000 {built-in method torch.get_default_dtype}\n",
      "101000/50500    0.261    0.000    0.292    0.000 {built-in method torch.randint}\n",
      "202000/101000    0.868    0.000    0.934    0.000 {built-in method torch.tensor}\n",
      "101000/50500    0.240    0.000    0.273    0.000 {built-in method torch.zeros}\n",
      "   252501    0.019    0.000    0.019    0.000 {function _ParameterMeta.__instancecheck__ at 0x78550f1d8040}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "    50500    0.141    0.000    0.141    0.000 {method 'add_' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.StringIO' objects}\n",
      "3000/1500    0.002    0.000    0.003    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "   959507    0.089    0.000    0.089    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
      "3000/1500    0.012    0.000    0.013    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "101000/50500    0.138    0.000    0.156    0.000 {method 'log' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'poll' of 'select.epoll' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "    50500    0.078    0.000    0.078    0.000 {method 'remainder' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "101000/50500    0.111    0.000    0.128    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "3000/1500    0.004    0.000    0.005    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "202000/101000    0.157    0.000    0.190    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.dump_stats(\"profilestats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Ground states not loaded yet. See load_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mcalculate_mse_step(Hamiltonians[\u001b[38;5;241m0\u001b[39m], params\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m), use_symmetry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised.py:180\u001b[0m, in \u001b[0;36mOptimizer.calculate_mse_step\u001b[0;34m(self, H, params, basis_batch, use_symmetry)\u001b[0m\n\u001b[1;32m    175\u001b[0m psi_predicted \u001b[38;5;241m=\u001b[39m amp\u001b[38;5;241m.\u001b[39mmul(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m phase))\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Obtain the ground state wave function for the Hamiltonian H, possibly memoized internally\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# in the Hamiltonian object. This is the true wave function that the model's predictions\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# are compared against. TODO: implement memoization in Hamiltonian objects.\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m energy, psi_true \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39mretrieve_ground(param\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Compute the mean squared error between the model's predictions and the true\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# ground state wave function.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m psi_predicted_real_imag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(psi_predicted)\n",
      "File \u001b[0;32m~/Projects/tqs/Ising.py:260\u001b[0m, in \u001b[0;36mIsing.retrieve_ground\u001b[0;34m(self, param, abs_tol)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mGiven a parameter value and system size, retrieves the ground state as a PyTorch tensor--\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mpossibly for use in supervised training.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    The ground state wavefunction as a PyTorch tensor of shape (2**n, )\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround states not loaded yet. See load_dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Find the rows close to the parameter value (within abs_tol)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m h_matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[np\u001b[38;5;241m.\u001b[39misclose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m], param, atol\u001b[38;5;241m=\u001b[39mabs_tol)]\n",
      "\u001b[0;31mValueError\u001b[0m: Ground states not loaded yet. See load_dataset."
     ]
    }
   ],
   "source": [
    "loss = opt.calculate_mse_step(\n",
    "    Hamiltonians[0], params=torch.tensor([1.0], device=\"cuda\"), use_symmetry=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Hamiltonians[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import compute_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m basis \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39mbasis \n\u001b[1;32m      2\u001b[0m symmetry \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39msymmetry\n\u001b[0;32m----> 3\u001b[0m log_amp, log_phase \u001b[38;5;241m=\u001b[39m compute_psi(testmodel, basis, symmetry)\n",
      "File \u001b[0;32m~/Projects/tqs/model_utils.py:228\u001b[0m, in \u001b[0;36mcompute_psi\u001b[0;34m(model, samples, symmetry, check_duplicate)\u001b[0m\n\u001b[1;32m    225\u001b[0m batch_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(batch)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, batch)\n\u001b[1;32m    226\u001b[0m spin_idx \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m--> 228\u001b[0m log_amp, log_phase \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    229\u001b[0m     samples, compute_phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    230\u001b[0m )  \u001b[38;5;66;03m# (seq, batch, phys_dim)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Ignore the last output (would be a conditional probability of an\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# n+1th spin given the first n spins and the coupling constants, but\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# our system only has n spins).\u001b[39;00m\n\u001b[1;32m    235\u001b[0m log_amp \u001b[38;5;241m=\u001b[39m log_amp[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# (n, batch, phys_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/model.py:304\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, spins, compute_phase)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m    303\u001b[0m     src_i \u001b[38;5;241m=\u001b[39m src[:, i \u001b[38;5;241m*\u001b[39m minibatch : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m minibatch]\n\u001b[0;32m--> 304\u001b[0m     src_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src_i) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_size\n\u001b[1;32m    306\u001b[0m     )  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;66;03m# src_i = src_i + self.pos_embedding[:len(src_i)]  # (seq, batch, embedding)\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     src_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src_i, system_size)  \u001b[38;5;66;03m# (seq, batch, embedding)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "basis = H.basis\n",
    "symmetry = H.symmetry\n",
    "log_amp, log_phase = compute_psi(testmodel, basis, symmetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 1,  ..., 0, 1, 1],\n",
       "        [0, 1, 0,  ..., 1, 0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spins = H.basis\n",
    "spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.src_mask.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .forward()\n",
    "\n",
    "Let's follow .forward() to find bottlenecks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Hamiltonians[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 1,  ..., 0, 1, 1],\n",
       "        [0, 1, 0,  ..., 1, 0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spins = H.basis\n",
    "spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.set_param(system_size=H.system_size, param=torch.tensor([1.0], device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.9957, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.wrap_spins(spins)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 1048576, 6])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.src_mask = testmodel._generate_square_subsequent_mask(src.size(0)).to(\n",
    "    src.device\n",
    ")\n",
    "testmodel.src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(testmodel.n_dim)\n",
    "print(testmodel.phys_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9957], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = src[\n",
    "    : testmodel.n_dim, 0, testmodel.phys_dim : testmodel.phys_dim + testmodel.n_dim\n",
    "].diag()\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = system_size.exp().round().to(torch.int64)\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src \u001b[38;5;241m=\u001b[39m testmodel\u001b[38;5;241m.\u001b[39mencoder(src) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(testmodel\u001b[38;5;241m.\u001b[39membedding_size)\n\u001b[1;32m      2\u001b[0m src\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "src = testmodel.encoder(src) * math.sqrt(testmodel.embedding_size)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694],\n",
       "         [-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694],\n",
       "         [-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694],\n",
       "         ...,\n",
       "         [-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694],\n",
       "         [-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694],\n",
       "         [-1.2558, -0.1955, -0.1439,  ...,  0.7043,  1.1742,  0.7694]],\n",
       "\n",
       "        [[ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269],\n",
       "         [ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269],\n",
       "         [ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269],\n",
       "         ...,\n",
       "         [ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269],\n",
       "         [ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269],\n",
       "         [ 0.0594, -0.1669, -0.1766,  ..., -0.3560, -0.3450, -0.0269]],\n",
       "\n",
       "        [[ 0.1011,  1.4968,  0.0705,  ...,  0.9532, -0.0762,  0.9932],\n",
       "         [ 0.1011,  1.4968,  0.0705,  ...,  0.9532, -0.0762,  0.9932],\n",
       "         [ 0.1011,  1.4968,  0.0705,  ...,  0.9532, -0.0762,  0.9932],\n",
       "         ...,\n",
       "         [ 0.0706,  0.9873,  0.3307,  ...,  1.2134,  0.5056,  0.5697],\n",
       "         [ 0.0706,  0.9873,  0.3307,  ...,  1.2134,  0.5056,  0.5697],\n",
       "         [ 0.0706,  0.9873,  0.3307,  ...,  1.2134,  0.5056,  0.5697]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8603,  0.2217, -0.0641,  ...,  0.9532, -0.0732,  0.9932],\n",
       "         [-0.8603,  0.2217, -0.0641,  ...,  0.9532, -0.0732,  0.9932],\n",
       "         [-0.8603,  0.2217, -0.0641,  ...,  0.9532, -0.0732,  0.9932],\n",
       "         ...,\n",
       "         [-0.8908, -0.2879,  0.1961,  ...,  1.2134,  0.5086,  0.5697],\n",
       "         [-0.8908, -0.2879,  0.1961,  ...,  1.2134,  0.5086,  0.5697],\n",
       "         [-0.8908, -0.2879,  0.1961,  ...,  1.2134,  0.5086,  0.5697]],\n",
       "\n",
       "        [[-0.6499,  1.1572, -0.5717,  ...,  0.9531, -0.0730,  0.9932],\n",
       "         [-0.6499,  1.1572, -0.5717,  ...,  0.9531, -0.0730,  0.9932],\n",
       "         [-0.6804,  0.6476, -0.3115,  ...,  1.2134,  0.5088,  0.5697],\n",
       "         ...,\n",
       "         [-0.6499,  1.1572, -0.5717,  ...,  0.9531, -0.0730,  0.9932],\n",
       "         [-0.6804,  0.6476, -0.3115,  ...,  1.2134,  0.5088,  0.5697],\n",
       "         [-0.6804,  0.6476, -0.3115,  ...,  1.2134,  0.5088,  0.5697]],\n",
       "\n",
       "        [[ 0.2510,  1.4855, -0.8815,  ...,  0.9531, -0.0728,  0.9932],\n",
       "         [ 0.2205,  0.9760, -0.6213,  ...,  1.2134,  0.5090,  0.5697],\n",
       "         [ 0.2510,  1.4855, -0.8815,  ...,  0.9531, -0.0728,  0.9932],\n",
       "         ...,\n",
       "         [ 0.2205,  0.9760, -0.6213,  ...,  1.2134,  0.5090,  0.5697],\n",
       "         [ 0.2510,  1.4855, -0.8815,  ...,  0.9531, -0.0728,  0.9932],\n",
       "         [ 0.2205,  0.9760, -0.6213,  ...,  1.2134,  0.5090,  0.5697]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.pos_encoder(src)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m testmodel\u001b[38;5;241m.\u001b[39mtransformer_encoder(src, testmodel\u001b[38;5;241m.\u001b[39msrc_mask)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, src_mask\u001b[38;5;241m=\u001b[39mmask, is_causal\u001b[38;5;241m=\u001b[39mis_causal, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:119\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m    120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Projects/tqs/custom_transformer_layer.py:128\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: Tensor, attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    129\u001b[0m         x,\n\u001b[1;32m    130\u001b[0m         x,\n\u001b[1;32m    131\u001b[0m         x,\n\u001b[1;32m    132\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    133\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    134\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:142\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     87\u001b[0m             query: Tensor,\n\u001b[1;32m     88\u001b[0m             key: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m             attn_mask: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m             average_attn_weights: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Optional[Tensor]]:\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mNote::\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Please, refer to :func:`~torch.nn.MultiheadAttention.forward` for more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m      head of shape :math:`(N, num_heads, L, S)`.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(query, key, value, key_padding_mask,\n\u001b[1;32m    143\u001b[0m                               need_weights, attn_mask, average_attn_weights)\n",
      "File \u001b[0;32m~/Projects/tqs/custom_modules.py:165\u001b[0m, in \u001b[0;36mMultiheadAttention._forward_impl\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m    162\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (query, key, value)]\n\u001b[1;32m    164\u001b[0m tgt_len, bsz, embed_dim_to_check \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# allow MHA to have different sizes for the feature dimension\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m key\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m value\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m value\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# output = testmodel.transformer_encoder(src, testmodel.src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
